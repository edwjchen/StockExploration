{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy import linalg\n",
    "from sklearn.linear_model import Ridge\n",
    "from pytrends.request import TrendReq\n",
    "import os.path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/50786266/writing-dictionary-of-dataframes-to-file\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def save_dict_df(dictex, keys_filename=\"stock_keys.txt\", data_folder=\"hourly_stock_data\"):\n",
    "    for key, val in dictex.items():\n",
    "        val.to_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)))\n",
    "\n",
    "    with open(keys_filename, \"w\") as f: #saving keys to file\n",
    "        f.write(str(list(dictex.keys())))\n",
    "\n",
    "def load_dict_df(keys_filename=\"stock_keys.txt\", data_folder=\"hourly_stock_data\"):\n",
    "    \"\"\"Reading data from keys\"\"\"\n",
    "    with open(keys_filename, \"r\") as f:\n",
    "        keys = eval(f.read())\n",
    "\n",
    "    dictex = {}    \n",
    "    for key in keys:\n",
    "        dictex[key] = pd.read_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)), index_col=0)\n",
    "\n",
    "    return dictex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['tesla', 'facebook', 'microsoft', 'amazon', 'google', 'uber', 'lyft', 'apple', 'snap']\n",
    "key_terms = ['report', 'good', 'bad', 'up', 'down', 'stock']\n",
    "company_symbol = ['TSLA', 'FB', 'MSFT', 'AMZN', 'GOOGL', 'UBER', 'LYFT', 'AAPL', 'SNAP']\n",
    "stock_columns = ['open', 'high', 'low', 'close', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create kw_list \n",
    "kw_list = []\n",
    "for c_name in companies:\n",
    "    for k in key_terms:\n",
    "        kw_list.append(c_name + \" \" + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3-month ago trend data. May need to run a couple times to make sure it doesn't time out. \n",
    "def getTrendDataDF(kw_list, pull_data=False, dates='today 3-m', pytrends_df_filename=\"hourly_pytrends.csv\"):\n",
    "    # Retrieve the cached trend data\n",
    "    if not pull_data and os.path.isfile(pytrends_df_filename):\n",
    "        df = pd.read_csv(pytrends_df_filename, index_col=\"date\")\n",
    "        \n",
    "    else: # Construct the dataframe by making pytrends calls\n",
    "        df = pd.DataFrame()\n",
    "        data = {}\n",
    "        #print(df.empty)\n",
    "        pytrends = TrendReq(hl='en-US', tz=360)\n",
    "        sleep = True\n",
    "        for kw in kw_list:\n",
    "            if 'apple' in kw and sleep:\n",
    "                time.sleep(60)\n",
    "                sleep = False\n",
    "            df_temp = pytrends.get_historical_interest([kw], year_start=2019, month_start=11, day_start=25, hour_start=0, year_end=2019, month_end=11, day_end=29, hour_end=23)\n",
    "            df_temp = df_temp.drop(['isPartial'], axis=1)\n",
    "            # print(kw)\n",
    "            data[kw] = df_temp\n",
    "        for kw in kw_list:\n",
    "            if df.empty:\n",
    "                df = data[kw]\n",
    "            else:\n",
    "                df = df.join(data[kw])\n",
    "        df.to_csv(pytrends_df_filename)\n",
    "    #reverse df rows\n",
    "    df = df.iloc[::-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Stock Hourly info for past 7 days\n",
    "def getHourlyStockInfoDict(company_symbol, pull_data=False, stock_df_filename=\"stock_keys.txt\"):\n",
    "    if not pull_data and os.path.isfile(stock_df_filename):\n",
    "        dict_stocks = load_dict_df(keys_filename=stock_df_filename);\n",
    "    else :\n",
    "        ts = 'TIME_SERIES_INTRADAY'\n",
    "        api_key = ''\n",
    "        interval = '30min'\n",
    "        outputsize = 'full'\n",
    "        dict_stocks = {}\n",
    "        for i, symbol in enumerate(company_symbol):\n",
    "            link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "                .format(ts, symbol, interval, api_key, outputsize)\n",
    "            request = requests.get(link)\n",
    "            data = json.loads(request.text)\n",
    "            # API only give you 5 requests per 5 mins, so break out if response is not what is expected.\n",
    "            while \"Time Series (30min)\" not in data:\n",
    "                print('...sleeping...')\n",
    "                time.sleep(70)\n",
    "                link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "                    .format(ts, symbol, interval, api_key, outputsize)\n",
    "                request = requests.get(link)\n",
    "                data = json.loads(request.text)\n",
    "            stock_data_per_hour = json.dumps(data[\"Time Series (30min)\"])\n",
    "            df_temp = pd.read_json(stock_data_per_hour).transpose()\n",
    "            df_temp.reset_index(level=0, inplace=True)\n",
    "            df_temp.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "            dict_stocks[companies[i]] = df_temp\n",
    "        save_dict_df(dict_stocks, keys_filename=stock_df_filename)\n",
    "    return dict_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrends(company_name, df_trends):\n",
    "    # Filters the trends\n",
    "    company_keywords =  [x for x in list(df_trends.columns.values) if company_name in x]\n",
    "    return df_trends[company_keywords].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJointTimes(df_stock, df_trends): \n",
    "    stock_times = df_stock['times']\n",
    "    trends_times = list(df_trends.index)\n",
    "    return list(set(stock_times) & set(trends_times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverlapDateData(company_name, dict_stocks, df_trends): \n",
    "    new_df_trends = getTrends(company_name, df_trends)\n",
    "    \n",
    "    joint_times = getJointTimes(dict_stocks[company_name], new_df_trends)\n",
    "    new_df_stocks = dict_stocks[company_name].loc[dict_stocks[company_name]['times'].isin(joint_times)]\n",
    "    new_df_stocks = new_df_stocks.reset_index() \n",
    "    \n",
    "    new_df_trends = new_df_trends.loc[new_df_trends.index.isin(joint_times)]\n",
    "    new_df_trends = new_df_trends.reset_index()\n",
    "    new_df_trends.columns = ['_'.join(x.split()) for x in list(new_df_trends.columns) if len(x) > 1]\n",
    "    df_all_data = new_df_stocks.join(new_df_trends)\n",
    "    return df_all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMultipleRegression(y_col, parameter_cols, training_data): \n",
    "    formula = y_col + ' ~ 1'\n",
    "    for i in parameter_cols: \n",
    "        formula = formula + \" + \" + i\n",
    "\n",
    "    result = sm.formula.ols(formula=formula, data=training_data).fit()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMultipleRegressionAndGetMSE(company, result, y_col, cols, all_data, training_data, testing_data):\n",
    "    y_pred = result.predict()\n",
    "    plt.plot(range(len(all_data[y_col])) , all_data[y_col])\n",
    "    plt.plot(range(19), result.predict(training_data[cols]), '-')\n",
    "    plt.plot(range(19, len(df_all_data[y_col])), result.predict(testing_data[cols]), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Output $ amount')\n",
    "    plt.title(company + ' Multiple Regression: ' + str(y_col))\n",
    "    plt.legend([\"True Data\",\"Training Data - Price change prediction\", \"Testing Data - Price change prediction\"])\n",
    "    plt.show()\n",
    "    \n",
    "    MSE = mean_squared_error(result.predict(testing_data[cols]), testing_data[y_col]) / (np.mean(testing_data[y_col]) * np.std(testing_data[y_col]))\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestAlphaRidgeRegression(y_col, parameter_cols, df_all_data_train):\n",
    "    df_all_data_test = df_all_data_train[15:]\n",
    "    df_all_data_train = df_all_data_train[:15]\n",
    "    \n",
    "    X = df_all_data_train[parameter_cols]\n",
    "    y = df_all_data_train[y_col]\n",
    "    alpha = []\n",
    "    MSE_train = []\n",
    "    MSE_test = []\n",
    "    for i in range(90, 2000, 10):\n",
    "        clf = Ridge(alpha=i)\n",
    "        clf.fit(X, y) \n",
    "        alpha.append(i)\n",
    "        MSE_train.append(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col]))\n",
    "        MSE_test.append(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col]))\n",
    "\n",
    "    bestAlpha = alpha[MSE_test.index(min(MSE_test))]\n",
    "    \n",
    "    print(\"alpha: \"+str(bestAlpha))\n",
    "    print(\"Training error = \"+str(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col])))\n",
    "    print(\"Testing error = \"+str(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col])))\n",
    "    print()\n",
    "    return bestAlpha, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge regression\n",
    "\n",
    "def trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, parameter_cols, df_all_data_train, df_all_data_test) : \n",
    "    bestAlpha, clf = getBestAlphaRidgeRegression(y_col, parameter_cols, df_all_data_train)\n",
    "    \n",
    "    X = df_all_data_train[parameter_cols]\n",
    "    y = df_all_data_train[y_col]\n",
    "    \n",
    "    #plot data with training and test data\n",
    "    clf = Ridge(alpha=bestAlpha)\n",
    "    clf.fit(X, y) \n",
    "    plt.plot(range(len(df_all_data[y_col])) , df_all_data[y_col])\n",
    "    plt.plot(range(19), clf.predict(df_all_data_train[cols]), '-')\n",
    "    plt.plot(range(19, len(df_all_data[y_col])), clf.predict(df_all_data_test[cols]), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Output $ amount')\n",
    "    plt.title(company + ' Ridge Regression: ' + str(y_col))\n",
    "    plt.legend([\"True Data\",\"Training Data - Price change prediction\", \"Testing Data - Price change prediction\"])\n",
    "    plt.show()\n",
    "    \n",
    "    print(clf.get_params())\n",
    "    MSE = mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col]) / (np.mean(df_all_data_test[y_col]) * np.std(df_all_data_test[y_col]))\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovingAvgAndStdDev(col_name, num_days, df_all_data):\n",
    "    # Moving average and stdev past X days\n",
    "    col_movingAvg = []\n",
    "    col_stdev = []\n",
    "    \n",
    "    num_days_to_average = 10\n",
    "    for i in range(len(df_all_data)):\n",
    "        sum_to_avg = 0\n",
    "        nums = []\n",
    "        num_to_avg = min(num_days_to_average, len(df_all_data) - i) - 1\n",
    "        for j in range(1, num_to_avg):\n",
    "            sum_to_avg += df_all_data[col][i + j]\n",
    "            nums.append(df_all_data[col][i + j])\n",
    "        avg = sum_to_avg / (num_to_avg if num_to_avg > 0 else 1)\n",
    "        stdev = np.std((nums if nums else [0]))\n",
    "\n",
    "        col_movingAvg.append(avg)\n",
    "        col_stdev.append(stdev)\n",
    "    return col_movingAvg, col_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParamCols(df_all_data):\n",
    "    cols = list(df_all_data.columns)\n",
    "    cols.remove('profit')\n",
    "    cols.remove('open')\n",
    "    cols.remove('close')\n",
    "    cols.remove('high')\n",
    "    cols.remove('low')\n",
    "    cols.remove('times')\n",
    "    cols.remove('date')\n",
    "    cols.remove('index')\n",
    "    cols.remove('volume')\n",
    "    cols.remove('mid')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trend data\n",
    "df_trends = getTrendDataDF(kw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock data\n",
    "dict_stocks = getHourlyStockInfoDict(company_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with all predictors, and only moving averages, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_dict = {} # {\"company\":{\"multipleRegressionProfit\":value, \"multipleRegressionCost\":value, etc}}\n",
    "# Join data together, train various models\n",
    "for company in companies[:1]: \n",
    "    print(company)\n",
    "    MSE_dict[company] = {}\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    \n",
    "    \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data)\n",
    "    \n",
    "    # Include moving average, stdev, and prev. 10 days. \n",
    "    num_days_to_average = 10\n",
    "    col = 'profit'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "    df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "    df_all_data[col+'_stdev'] = col_stdev\n",
    "    col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_all_data[col+'_prev'] = col_prev\n",
    "    \n",
    "    col = 'mid'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "    df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "    df_all_data[col+'_stdev'] = col_stdev\n",
    "    col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_all_data[col+'_prev'] = col_prev\n",
    "    \n",
    "    col = 'volume'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "    df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "    df_all_data[col+'_stdev'] = col_stdev\n",
    "    col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_all_data[col+'_prev'] = col_prev\n",
    "    \n",
    "    # Include movingAvg, stdev, and prev for all the Trends cols\n",
    "    for col in cols: \n",
    "        # Prev info\n",
    "        col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "        col_prev.append(0) # Append this so we can have 0 padding\n",
    "        df_all_data[col+'_prev'] = col_prev\n",
    "        \n",
    "        col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "        \n",
    "        df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "        df_all_data[col+'_stdev'] = col_stdev\n",
    "\n",
    "    \n",
    "    cols = getAllParamCols(df_all_data)\n",
    "        \n",
    "    # Reverse index order\n",
    "    df_all_data = df_all_data.iloc[::-1] \n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_all_data[:19]\n",
    "    df_all_data_test = df_all_data[19:]\n",
    "    \n",
    "    MSE_dict[company][\"MultipleRegression\"] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"] = {}\n",
    "    parameter_type = \"allPredictors\"\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type] = {}\n",
    "                         \n",
    "    # Multiple Regression, All Predictors\n",
    "    y_col='mid'\n",
    "    close_multiple_regression_res = trainMultipleRegression(y_col, cols, df_all_data_train)\n",
    "    print(close_multiple_regression_res.summary())\n",
    "    MSE = plotMultipleRegressionAndGetMSE(company, close_multiple_regression_res, y_col, cols, df_all_data, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    \n",
    "    # RIDGE REGRESSION REQUIRES STANDARDIZATION\n",
    "    # Standardize the input parameters\n",
    "    df_standardized_data = df_all_data.copy()\n",
    "\n",
    "    for col in cols: \n",
    "        df_standardized_data[col] = df_standardized_data[col] / np.std(df_standardized_data[col].values)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_standardized_data[:19]\n",
    "    df_all_data_test = df_standardized_data[19:]\n",
    "    \n",
    "    # Ridge Regression, All Predictors\n",
    "    MSE = trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, cols, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Predictions using only stock market data #### \n",
    "    # Remove any cols in col that has the company name in it. \n",
    "    print(\"No Trend Data\")\n",
    "    cols_noTrends = [col for col in cols if company not in col]\n",
    "    cols = cols_noTrends\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_all_data[:19]\n",
    "    df_all_data_test = df_all_data[19:]\n",
    "    \n",
    "    parameter_type = \"noTrend\"\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type] = {}\n",
    "    \n",
    "    # Multiple Regression\n",
    "    close_multiple_regression_res = trainMultipleRegression(y_col, cols, df_all_data_train)\n",
    "    print(close_multiple_regression_res.summary())\n",
    "    MSE = plotMultipleRegressionAndGetMSE(company, close_multiple_regression_res, y_col, cols, df_all_data, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    # Standardize the input parameters\n",
    "    df_standardized_data = df_all_data.copy()\n",
    "\n",
    "    for col in cols: \n",
    "        df_standardized_data[col] = df_standardized_data[col] / np.std(df_standardized_data[col].values)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_standardized_data[:19]\n",
    "    df_all_data_test = df_standardized_data[19:]\n",
    "    \n",
    "    # Ridge Regression\n",
    "    MSE = trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, cols, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with only Google Trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data together, train various models\n",
    "for company in companies[:1]: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    \n",
    "    \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data)\n",
    "    \n",
    "    num_days_to_average = 10\n",
    "    for col in cols: \n",
    "        # Prev to today increment amount\n",
    "        col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "        col_prev.append(0) # Append this so we can have 0 padding\n",
    "        df_all_data[col+'_prev'] = col_prev\n",
    "        \n",
    "        col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "        \n",
    "        df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "        df_all_data[col+'_stdev'] = col_stdev\n",
    "\n",
    "    \n",
    "    cols = getAllParamCols(df_all_data)\n",
    "        \n",
    "    # Reverse index order\n",
    "    df_all_data = df_all_data.iloc[::-1] \n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_all_data[:19]\n",
    "    df_all_data_test = df_all_data[19:]\n",
    "    \n",
    "    \n",
    "    parameter_type=\"onlyTrends\"\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type] = {}\n",
    "    y_col='mid'\n",
    "    \n",
    "    # Profit prediction: \n",
    "    close_multiple_regression_res = trainMultipleRegression(y_col, cols, df_all_data_train)\n",
    "    print(close_multiple_regression_res.summary())\n",
    "    MSE = plotMultipleRegressionAndGetMSE(company, close_multiple_regression_res, y_col, cols, df_all_data, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    # Standardize the input parameters\n",
    "    df_standardized_data = df_all_data.copy()\n",
    "\n",
    "    for col in cols: \n",
    "        df_standardized_data[col] = df_standardized_data[col] / np.std(df_standardized_data[col].values)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_standardized_data[:19]\n",
    "    df_all_data_test = df_standardized_data[19:]\n",
    "    \n",
    "    \n",
    "    # Ridge Regression\n",
    "    MSE = trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, cols, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMSE(y_col, model):\n",
    "    for company in companies[:1]:\n",
    "        plt.plot([\"all predictors\", \"only trends\", \"no trends\"], [MSE_dict[company][model]['allPredictors'][y_col],  MSE_dict[company][model]['onlyTrends'][y_col], MSE_dict[company][model]['noTrend'][y_col]], label=company)\n",
    "\n",
    "    plt.xlabel(\"parameter types\")\n",
    "    plt.ylabel(\"MSE / mean stock price\")\n",
    "    plt.legend()\n",
    "    plt.title(model + \" \" + y_col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"mid\"\n",
    "model = \"MultipleRegression\"\n",
    "plotMSE(y_col, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"mid\"\n",
    "model = \"RidgeRegression\"\n",
    "plotMSE(y_col, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow + Keras time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to be between 0-1 \n",
    "def predictCompany(df_temp, train_size, cols):\n",
    "    # scale data to be between 0-1 including average\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    data_set_scaled = sc.fit_transform(df_temp[cols+['mid']])\n",
    "    \n",
    "    #split training data \n",
    "    train = data_set_scaled[:train_size, :]\n",
    "    test = data_set_scaled[train_size:, :]\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    \n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(train_size, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "    #train model\n",
    "    history = model.fit(train_X, train_y, epochs=500, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "    return history, model, train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrediction(company, train_size, model, train_X, train_y, test_X, test_y):\n",
    "    plt.plot(range(len(train_y)+len(test_y)) , list(np.array(train_y))+list(np.array(test_y)), range(len(train_y)), model.predict(train_X), '-', range(len(train_y), len(train_y)+len(test_y)), model.predict(test_X), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Profit from previous day')\n",
    "    plt.title(company + ' - predicting stock market with Keras')\n",
    "    plt.legend([\"True Data\",\"Training Data\", \"Testing Data\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trends only!\n",
    "MSE_train_trends_only = []\n",
    "MSE_test_trends_only = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data)\n",
    "    \n",
    "    # Plotting only Google Trends data \n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(df_all_data, 19, cols)\n",
    "    plotHistory(history)\n",
    "    plotPrediction(company, 19, model, train_X, train_y, test_X, test_y)\n",
    "    MSE_train_trends_only.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_trends_only.append((company, mean_squared_error(model.predict(test_X), test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock only!\n",
    "MSE_train_stock_only = []\n",
    "MSE_test_stock_only = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = stock_columns\n",
    "    \n",
    "    # Plotting only Google Trends data \n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(df_all_data, 19, cols)\n",
    "    plotHistory(history)\n",
    "    plotPrediction(company, 19, model, train_X, train_y, test_X, test_y)\n",
    "    MSE_train_stock_only.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_stock_only.append((company, mean_squared_error(model.predict(test_X), test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both trends and stock!\n",
    "MSE_train_both = []\n",
    "MSE_test_both = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data) + stock_columns\n",
    "    \n",
    "    # Plotting only Google Trends data \n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(df_all_data, 19, cols)\n",
    "    plotHistory(history)\n",
    "    plotPrediction(company, 19, model, train_X, train_y, test_X, test_y)\n",
    "    MSE_train_both.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_both.append((company, mean_squared_error(model.predict(test_X), test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot MSE_train data points as scatter plots\n",
    "X = [x[0] for x in MSE_train_both]\n",
    "trends_only = [x[1] for x in MSE_train_trends_only]\n",
    "stock_only = [x[1] for x in MSE_train_stock_only]\n",
    "both = [x[1] for x in MSE_train_both]\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(X,trends_only, '.', X, stock_only, '^', X, both, '.')\n",
    "plt.xlabel('Companies')\n",
    "plt.ylabel('MSE Train')\n",
    "plt.title('MSE Train per company training on a Keras model')\n",
    "ax.legend(['trends only', 'stock_only', 'both'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot MSE_test data points as scatter plots\n",
    "X = [x[0] for x in MSE_test_both]\n",
    "trends_only = [x[1] for x in MSE_test_trends_only]\n",
    "stock_only = [x[1] for x in MSE_test_stock_only]\n",
    "both = [x[1] for x in MSE_test_both]\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(X,trends_only, '.', X, stock_only, '^', X, both, '.')\n",
    "plt.xlabel('Companies')\n",
    "plt.ylabel('MSE Test')\n",
    "plt.title('MSE Test per company training on a Keras model')\n",
    "ax.legend(['trends only', 'stock_only', 'both'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression with Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy import linalg\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from pytrends.request import TrendReq\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_df(dictex, keys_filename=\"keys.txt\", data_folder=\"hourly_stock_data\"):\n",
    "    for key, val in dictex.items():\n",
    "        val.to_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)))\n",
    "\n",
    "    with open(keys_filename, \"w\") as f: #saving keys to file\n",
    "        f.write(str(list(dictex.keys())))\n",
    "\n",
    "def load_dict_df(keys_filename=\"keys.txt\", data_folder=\"hourly_stock_data\"):\n",
    "    \"\"\"Reading data from keys\"\"\"\n",
    "    with open(keys_filename, \"r\") as f:\n",
    "        keys = eval(f.read())\n",
    "\n",
    "    dictex = {}    \n",
    "    for key in keys:\n",
    "        dictex[key] = pd.read_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)), index_col=0)\n",
    "\n",
    "    return dictex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrends(company_name, df_trends):\n",
    "    # Filters the trends\n",
    "    company_keywords =  [x for x in list(df_trends.columns.values) if company_name in x]\n",
    "    return df_trends[company_keywords].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJointTimes(df_stock, df_trends): \n",
    "    stock_times = df_stock['times']\n",
    "    trends_times = list(df_trends.index)\n",
    "    return list(set(stock_times) & set(trends_times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Company Keyterms and Symbols\n",
    "companies = ['tesla', 'facebook', 'microsoft', 'amazon', 'google', 'uber', 'lyft','apple','snap']\n",
    "key_terms = ['report', 'good', 'bad', 'up', 'down', 'stock']\n",
    "company_symbol = ['TSLA', 'FB', 'MSFT', 'AMZN', 'GOOGL', 'UBER', 'LYFT','AAPL','SNAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Key Word List\n",
    "kw_list = []\n",
    "for c_name in companies:\n",
    "    for k in key_terms:\n",
    "        kw_list.append(c_name + \" \" + k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather Google trends data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Hourly trends data from pytrends\n",
    "# If there is a server 500 error, try changing the dates to this past week! \n",
    "def getHourlyTrends(company_symbol, pull_data=False, trends_df_filename=\"hourly_pytrends.csv\"):\n",
    "    if not pull_data and os.path.isfile(trends_df_filename):\n",
    "        trends_df = pd.read_csv(trends_df_filename, index_col=\"date\")\n",
    "    else :\n",
    "        df = pd.DataFrame()\n",
    "        data = {}\n",
    "        pytrends = TrendReq(hl='en-US', tz=360)\n",
    "        for kw in kw_list:\n",
    "            print(kw)\n",
    "            df_temp = pytrends.get_historical_interest([kw], year_start=2019, month_start=11, day_start=27, hour_start=0, year_end=2019, month_end=12, day_end=3, hour_end=23, sleep=30)\n",
    "            if 'isPartial' in df_temp.columns: \n",
    "                df_temp = df_temp.drop(['isPartial'], axis=1)\n",
    "            data[kw] = df_temp\n",
    "        for kw in kw_list:\n",
    "            if df.empty:\n",
    "                df = data[kw]\n",
    "            else:\n",
    "                df = df.join(data[kw])\n",
    "                \n",
    "        print(\"finished kw forloop\")\n",
    "        trends_df = df\n",
    "        df.to_csv(trends_df_filename)\n",
    "    return trends_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trends = getHourlyTrends(company_symbol,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Data\n",
    "df_trends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather Stock Data: Alpha Vantage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Stock Hourly info for past 7 days\n",
    "def getHourlyStockInfoDict(company_symbol, pull_data=False, stock_df_filename=\"stock_keys.txt\"):\n",
    "    if not pull_data and os.path.isfile(stock_df_filename):\n",
    "        dict_stocks = load_dict_df(keys_filename=stock_df_filename);\n",
    "    else :\n",
    "        ts = 'TIME_SERIES_INTRADAY'\n",
    "        api_key = ''\n",
    "        interval = '30min'\n",
    "        outputsize = 'full'\n",
    "        dict_stocks = {}\n",
    "        for i, symbol in enumerate(company_symbol):\n",
    "            print(symbol)\n",
    "            link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "                .format(ts, symbol, interval, api_key, outputsize)\n",
    "            request = requests.get(link)\n",
    "            data = json.loads(request.text)\n",
    "            # API only give you 5 requests per 5 mins, so break out if response is not what is expected.\n",
    "            while \"Time Series (30min)\" not in data:\n",
    "                print('...sleeping...')\n",
    "                time.sleep(70)\n",
    "                link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "                    .format(ts, symbol, interval, api_key, outputsize)\n",
    "                request = requests.get(link)\n",
    "                data = json.loads(request.text)\n",
    "            stock_data_per_hour = json.dumps(data[\"Time Series (30min)\"])\n",
    "            df_temp = pd.read_json(stock_data_per_hour).transpose()\n",
    "            df_temp.reset_index(level=0, inplace=True)\n",
    "            df_temp.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "            dict_stocks[companies[i]] = df_temp\n",
    "        save_dict_df(dict_stocks, keys_filename=stock_df_filename)\n",
    "    return dict_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_stocks = getHourlyStockInfoDict(company_symbol,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather stock data for each individual company\n",
    "#df_stocks = {}\n",
    "#for s in company_symbol:\n",
    "#    print(s)\n",
    "#    res = getIntraday1minDF(s)\n",
    "    # data limit reached\n",
    "#    while res.empty:\n",
    "#        time.sleep(10)\n",
    "#        res = getIntraday1minDF(s)\n",
    "    # add stock information to dictionary\n",
    "#    df_stocks[s] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview Stock Data\n",
    "df_stocks['tesla'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse df rows\n",
    "df_trends = df_trends.iloc[::-1]\n",
    "df_trends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge Trend and Stock Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trends_stocks = {}\n",
    "def cleanAndJoinData():\n",
    "    for s,c in zip(company_symbol, companies):\n",
    "        print(c)\n",
    "        company_names = [x for x in list(df_trends.columns.values) if c in x]\n",
    "        df_temp_trends = df_trends[company_names]\n",
    "        \n",
    "        # line up indexes \n",
    "        stock_times = list(df_stocks[c].times)\n",
    "        trends_times = list(df_temp_trends.index)\n",
    "        joint_times = list(set(stock_times) & set(trends_times)) \n",
    "        \n",
    "        print(joint_times)\n",
    "        df_temp_stocks = df_stocks[c].loc[df_stocks[c]['times'].isin(joint_times)]\n",
    "        df_temp_stocks = df_temp_stocks.reset_index()\n",
    "        df_temp_stocks = df_temp_stocks.iloc[::-1]\n",
    "        df_temp_trends = df_temp_trends.loc[df_temp_trends.index.isin(joint_times)]\n",
    "        df_temp_trends = df_temp_trends.reset_index()\n",
    "        df_temp_trends.columns = ['_'.join(x.split()) for x in list(df_temp_trends.columns) if len(x) > 1]\n",
    "        df_trends_stocks[c] = df_temp_stocks.join(df_temp_trends,lsuffix='_left', rsuffix='_right')\n",
    "cleanAndJoinData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for calculating new predictors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovingAvgAndStdDev(col_name, num_days, df_all_data):\n",
    "    # Moving average and stdev past X days\n",
    "    col_movingAvg = []\n",
    "    col_stdev = []\n",
    "    \n",
    "    num_days_to_average = 10\n",
    "    for i in range(len(df_all_data)):\n",
    "        sum_to_avg = 0\n",
    "        nums = []\n",
    "        num_to_avg = min(num_days_to_average, len(df_all_data) - i) - 1\n",
    "        for j in range(1, num_to_avg):\n",
    "            sum_to_avg += df_all_data[col][i + j]\n",
    "            nums.append(df_all_data[col][i + j])\n",
    "        avg = sum_to_avg / (num_to_avg if num_to_avg > 0 else 1)\n",
    "        stdev = np.std((nums if nums else [0]))\n",
    "\n",
    "        col_movingAvg.append(avg)\n",
    "        col_stdev.append(stdev)\n",
    "    return col_movingAvg, col_stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Additional Predictors to model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParamCols(df_all_data):\n",
    "    cols = list(df_all_data.columns)\n",
    "    cols.remove('open')\n",
    "    cols.remove('close')\n",
    "    cols.remove('high')\n",
    "    cols.remove('low')\n",
    "    cols.remove('times')\n",
    "    cols.remove('date')\n",
    "    cols.remove('index')\n",
    "    cols.remove('volume')\n",
    "    cols.remove('profit')\n",
    "    cols.remove('mid')\n",
    "    cols.remove('volume_movingAvg')\n",
    "    cols.remove('volume_stdev')\n",
    "    cols.remove('profit_movingAvg')\n",
    "    cols.remove('profit_stdev')\n",
    "    cols.remove('mid_movingAvg')\n",
    "    cols.remove('mid_stdev')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictors\n",
    "for company in df_trends_stocks: \n",
    "    # Calculate Profit For Each Company in Dict\n",
    "    (df_trends_stocks[company])['profit'] = (df_trends_stocks[company])['open']-(df_trends_stocks[company])['close']\n",
    "    (df_trends_stocks[company])['mid'] = ((df_trends_stocks[company])['high']+(df_trends_stocks[company])['low'])/2\n",
    "    # Calculate Moving Averages and Standard Deviation for Stock Data\n",
    "    # For Profit\n",
    "    num_days_to_average = 10\n",
    "    col = 'profit'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "    (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "    (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_trends_stocks[company][col+'_prev'] = col_prev\n",
    "    # For Mid\n",
    "    col = 'mid'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "    (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "    (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_trends_stocks[company][col+'_prev'] = col_prev\n",
    "    # For Volume\n",
    "    col = 'volume'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "    (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "    (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    cols = getAllParamCols(df_trends_stocks[company])\n",
    "    col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_trends_stocks[company][col+'_prev'] = col_prev\n",
    "    \n",
    "    # Calculate Increment Over time\n",
    "    for col in cols: \n",
    "        # Prev \n",
    "        col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "        col_prev.append(0) # Append this so we can have 0 padding\n",
    "        #df_all_data[col+'_prev'] = col_prev\n",
    "        (df_trends_stocks[company])[col+'_prev'] = col_prev\n",
    "        col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "        \n",
    "        (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "        (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    # Reverse index order\n",
    "    df_trends_stocks[company] = df_trends_stocks[company].iloc[::-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LASSO Regression Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for LASSO Regression\n",
    "def getBestAlphaLASSORegression(y_col, parameter_cols, df_all_data_train):\n",
    "    split = int(df_all_data_train.shape[0]/2)\n",
    "    df_all_data_test = df_all_data_train[split:]\n",
    "    df_all_data_train = df_all_data_train[:split]\n",
    "    \n",
    "    X = df_all_data_train[parameter_cols]\n",
    "    y = df_all_data_train[y_col]\n",
    "    alpha = []\n",
    "    MSE_train = []\n",
    "    MSE_test = []\n",
    "    for i in range(90, 10000, 10):\n",
    "        clf = linear_model.Lasso(alpha=i)\n",
    "        clf.fit(X, y) \n",
    "        alpha.append(i)\n",
    "        MSE_train.append(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col]))\n",
    "        MSE_test.append(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col]))\n",
    "\n",
    "    bestAlpha = alpha[MSE_test.index(min(MSE_test))]\n",
    "    bestMSE = min(MSE_test)\n",
    "    print(\"alpha: \"+str(bestAlpha))\n",
    "    print(\"Training error = \"+str(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col])))\n",
    "    print(\"Testing error = \"+str(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col])))\n",
    "    print()\n",
    "    return bestAlpha, bestMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions For Plotting LASSO Regression\n",
    "def plotLASSO(company, alpha, label, predictors, df): \n",
    "    # Separate Data\n",
    "    split = int(df.shape[0]/2)\n",
    "    df_train = df[:split]\n",
    "    df_test = df[split:]\n",
    "    X_train = df_train[predictors]\n",
    "    Y_train = df_train[label]\n",
    "    X_test = df_test[predictors]\n",
    "    Y_test = df_test[label]\n",
    "    Y_labels = df[label]\n",
    "    # Initialize Model w/ Optimal Alpha\n",
    "    clf = linear_model.Lasso(alpha=alpha)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    param_dict = dict(zip(clf.coef_, predictors))\n",
    "    print(\"Parameter Estimates w/ LASSO : \",param_dict)\n",
    "    # Make Predictions using optimal alpha value\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    # Plot test and train predictions against true labels\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.plot(range(split), y_pred_train, color='r')\n",
    "    ax1.plot(range(split, len(Y_labels)),y_pred_test, color='b')\n",
    "    ax1.plot(range(len(Y_labels)),Y_labels, color='g')\n",
    "    ax1.set_xlabel('Time in Hours')\n",
    "    ax1.set_ylabel(label)\n",
    "    ax1.set_title(label + ' Predictions with LASSO Regression for '+ company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run regression and view dropped features for each company**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnsAll(company, label): \n",
    "    cols = df_trends_stocks[company].columns\n",
    "    cols = list(cols)\n",
    "    cols.remove('times')\n",
    "    cols.remove('index')\n",
    "    cols.remove('date')\n",
    "    cols.remove(label)\n",
    "    return cols\n",
    "\n",
    "def columnsTrends(company, label): \n",
    "    cols = [x for x in list(df_trends_stocks[company].columns) if company in x]\n",
    "    return cols\n",
    "\n",
    "def columnsAverage(company, label): \n",
    "    cols = [x for x in list(df_trends_stocks[company].columns) if company not in x]\n",
    "    cols.remove(label)\n",
    "    cols.remove('times')\n",
    "    cols.remove('index')\n",
    "    cols.remove('date')\n",
    "    cols.remove('open')\n",
    "    cols.remove('volume')\n",
    "    cols.remove('high')\n",
    "    cols.remove('low')\n",
    "    cols.remove('close')\n",
    "    cols.remove('profit')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions w/ All Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['All Predictors ', 'Just Trends ','Just Stock Data']\n",
    "MSE = {key: None for key in keys}\n",
    "MSE_companies = {company: MSE for company in companies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for company in companies: \n",
    "    # Prepare column list\n",
    "    cols = columnsAll(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha, MSE = getBestAlphaLASSORegression('mid',cols,df_trends_stocks[company])\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_trends_stocks[company])\n",
    "    # Plot MSE for LASSO Regression\n",
    "    MSE_companies[company]['All Predictors']  = MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions for Just Trends Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for company in companies: \n",
    "    # Prepare column list\n",
    "    cols = columnsTrends(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha = getBestAlphaLASSORegression('mid',cols,df_trends_stocks[company])\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_trends_stocks[company])\n",
    "    # Plot MSE train and test for LASSO Regression\n",
    "    MSE_companies[company]['Just Trends']  = MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions for Just Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for company in companies: \n",
    "    # Prepare column list\n",
    "    cols = columnsAverage(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha = getBestAlphaLASSORegression('mid',cols,df_trends_stocks[company])\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_trends_stocks[company])\n",
    "    # Plot MSE train and test for LASSO Regression\n",
    "    MSE_companies[company]['Just Stock Data']  = MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE_companies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
