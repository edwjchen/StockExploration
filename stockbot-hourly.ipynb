{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression with Hourly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy import linalg\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from pytrends.request import TrendReq\n",
    "import os.path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_df(dictex, keys_filename=\"keys.txt\", data_folder=\"hourly_stock_data\"):\n",
    "    for key, val in dictex.items():\n",
    "        val.to_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)))\n",
    "\n",
    "    with open(keys_filename, \"w\") as f: #saving keys to file\n",
    "        f.write(str(list(dictex.keys())))\n",
    "\n",
    "def load_dict_df(keys_filename=\"keys.txt\", data_folder=\"hourly_stock_data\"):\n",
    "    \"\"\"Reading data from keys\"\"\"\n",
    "    with open(keys_filename, \"r\") as f:\n",
    "        keys = eval(f.read())\n",
    "\n",
    "    dictex = {}    \n",
    "    for key in keys:\n",
    "        dictex[key] = pd.read_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)), index_col=0)\n",
    "\n",
    "    return dictex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrends(company_name, df_trends):\n",
    "    # Filters the trends\n",
    "    company_keywords =  [x for x in list(df_trends.columns.values) if company_name in x]\n",
    "    return df_trends[company_keywords].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJointTimes(df_stock, df_trends): \n",
    "    stock_times = df_stock['times']\n",
    "    trends_times = list(df_trends.index)\n",
    "    return list(set(stock_times) & set(trends_times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Company Keyterms and Symbols\n",
    "companies = ['tesla', 'facebook', 'microsoft', 'amazon', 'google', 'uber', 'lyft', 'apple', 'snap']\n",
    "key_terms = ['report', 'good', 'bad', 'up', 'down', 'stock']\n",
    "company_symbol = ['TSLA', 'FB', 'MSFT', 'AMZN', 'GOOGL', 'UBER', 'LYFT', 'AAPL', 'SNAP']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Key Word List\n",
    "kw_list = []\n",
    "for c_name in companies:\n",
    "    for k in key_terms:\n",
    "        kw_list.append(c_name + \" \" + k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather Google trends data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Hourly trends data from pytrends\n",
    "# If there is a server 500 error, try changing the dates to this past week! \n",
    "\n",
    "def getHourlyTrends(company_symbol, pull_data=False, trends_df_filename=\"hourly_pytrends.csv\"):\n",
    "    if not pull_data and os.path.isfile(trends_df_filename):\n",
    "        trends_df = pd.read_csv(trends_df_filename, index_col=\"date\")\n",
    "    else :\n",
    "        df = pd.DataFrame()\n",
    "        data = {}\n",
    "        pytrends = TrendReq(hl='en-US', tz=360)\n",
    "        for kw in kw_list:\n",
    "            print(kw)\n",
    "            df_temp = pytrends.get_historical_interest([kw], year_start=2019, month_start=11, day_start=28, hour_start=0, year_end=2019, month_end=12, day_end=4, hour_end=23)\n",
    "            if 'isPartial' in df_temp.columns: \n",
    "                df_temp = df_temp.drop(['isPartial'], axis=1)\n",
    "            data[kw] = df_temp\n",
    "        for kw in kw_list:\n",
    "            if df.empty:\n",
    "                df = data[kw]\n",
    "            else:\n",
    "                df = df.join(data[kw])\n",
    "                \n",
    "        print(\"finished kw forloop\")\n",
    "        trends_df = df\n",
    "        df.to_csv(trends_df_filename)\n",
    "    return trends_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trends = getHourlyTrends(company_symbol, pull_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect Data\n",
    "df_trends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gather Stock Data: Alpha Vantage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gather Stock Data for each company and return dataframe \n",
    "\n",
    "def getIntradayInfoDict(company_symbol, pull_data=False, stock_df_filename=\"hourly_stock_keys.txt\") :\n",
    "    if not pull_data and os.path.isfile(stock_df_filename):\n",
    "        dict_stocks = load_dict_df(keys_filename=stock_df_filename);\n",
    "    else :\n",
    "        dict_stocks = {}\n",
    "        ts = 'TIME_SERIES_INTRADAY'#'TIME_SERIES_DAILY'\n",
    "        interval = '30min'\n",
    "        api_key = 'OK92GXML7JXOOOFD' \n",
    "        outputsize = 'full' # compact= 100 results, full= all data (5 days?)\n",
    "        for i, symbol in enumerate(company_symbol):\n",
    "            link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "                .format(ts, symbol, interval, api_key, outputsize)\n",
    "            request = requests.get(link)\n",
    "            data = json.loads(request.text)\n",
    "            if \"Time Series (30min)\" not in data:\n",
    "                print(\"data limit reached. sleeping\")\n",
    "                time.sleep(70)\n",
    "                link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "                    .format(ts, symbol, interval, api_key, outputsize)\n",
    "                request = requests.get(link)\n",
    "                data = json.loads(request.text)\n",
    "            stock_data = json.dumps(data[\"Time Series (30min)\"])\n",
    "            df = pd.read_json(stock_data).transpose()\n",
    "            cols = ['1. open', '2. high', '3. low', '4. close', '5. volume']\n",
    "            df = df[cols]\n",
    "            df.reset_index(level=0, inplace=True)\n",
    "            df.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "            dict_stocks[companies[i]] = df\n",
    "        save_dict_df(dict_stocks, keys_filename=stock_df_filename)\n",
    "    return dict_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks = getIntradayInfoDict(company_symbol, pull_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse df rows\n",
    "df_stocks['tesla'] = df_stocks['tesla'].iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks['tesla'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge Trend and Stock Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_trends_stocks = {}\n",
    "def cleanAndJoinData():\n",
    "    for s,c in zip(company_symbol, companies):\n",
    "        print(c)\n",
    "        company_names = [x for x in list(df.columns.values) if c in x]\n",
    "        df_temp_trends = df[company_names]\n",
    "        \n",
    "        # line up indexes \n",
    "        stock_times = list(df_stocks[s].times)\n",
    "        trends_times = list(df_temp_trends.index)\n",
    "        joint_times = list(set(stock_times) & set(trends_times)) \n",
    "        \n",
    "        print(joint_times)\n",
    "        df_temp_stocks = df_stocks[s].loc[df_stocks[s]['times'].isin(joint_times)]\n",
    "        df_temp_stocks = df_temp_stocks.reset_index()\n",
    "        df_temp_stocks = df_temp_stocks.iloc[::-1]\n",
    "        df_temp_trends = df_temp_trends.loc[df_temp_trends.index.isin(joint_times)]\n",
    "        df_temp_trends = df_temp_trends.reset_index()\n",
    "        df_temp_trends.columns = ['_'.join(x.split()) for x in list(df_temp_trends.columns) if len(x) > 1]\n",
    "        df_trends_stocks[c] = df_temp_stocks.join(df_temp_trends,lsuffix='_left', rsuffix='_right')\n",
    "cleanAndJoinData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for calculating new predictors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovingAvgAndStdDev(col_name, num_days, df_all_data):\n",
    "    # Moving average and stdev past X days\n",
    "    col_movingAvg = []\n",
    "    col_stdev = []\n",
    "    \n",
    "    num_days_to_average = 10\n",
    "    for i in range(len(df_all_data)):\n",
    "        sum_to_avg = 0\n",
    "        nums = []\n",
    "        num_to_avg = min(num_days_to_average, len(df_all_data) - i) - 1\n",
    "        for j in range(1, num_to_avg):\n",
    "            sum_to_avg += df_all_data[col][i + j]\n",
    "            nums.append(df_all_data[col][i + j])\n",
    "        avg = sum_to_avg / (num_to_avg if num_to_avg > 0 else 1)\n",
    "        stdev = np.std((nums if nums else [0]))\n",
    "\n",
    "        col_movingAvg.append(avg)\n",
    "        col_stdev.append(stdev)\n",
    "    return col_movingAvg, col_stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Additional Predictors to model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParamCols(df_all_data):\n",
    "    cols = list(df_all_data.columns)\n",
    "    cols.remove('open')\n",
    "    cols.remove('close')\n",
    "    cols.remove('high')\n",
    "    cols.remove('low')\n",
    "    cols.remove('times')\n",
    "    cols.remove('date')\n",
    "    cols.remove('index')\n",
    "    cols.remove('volume')\n",
    "    cols.remove('profit')\n",
    "    cols.remove('mid')\n",
    "    cols.remove('volume_movingAvg')\n",
    "    cols.remove('volume_stdev')\n",
    "    cols.remove('profit_movingAvg')\n",
    "    cols.remove('profit_stdev')\n",
    "    cols.remove('mid_movingAvg')\n",
    "    cols.remove('mid_stdev')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictors\n",
    "for company in df_trends_stocks: \n",
    "    # Calculate Profit For Each Company in Dict\n",
    "    (df_trends_stocks[company])['profit'] = (df_trends_stocks[company])['open']-(df_trends_stocks[company])['close']\n",
    "    (df_trends_stocks[company])['mid'] = ((df_trends_stocks[company])['high']+(df_trends_stocks[company])['low'])/2\n",
    "    # Calculate Moving Averages and Standard Deviation for Stock Data\n",
    "    # For Profit\n",
    "    num_days_to_average = 10\n",
    "    col = 'profit'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "    (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "    (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_trends_stocks[company][col+'_prev'] = col_prev\n",
    "    # For Mid\n",
    "    col = 'mid'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "    (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "    (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_trends_stocks[company][col+'_prev'] = col_prev\n",
    "    # For Volume\n",
    "    col = 'volume'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "    (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "    (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    cols = getAllParamCols(df_trends_stocks[company])\n",
    "    col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_trends_stocks[company][col+'_prev'] = col_prev\n",
    "    \n",
    "    # Calculate Increment Over time\n",
    "    for col in cols: \n",
    "        # Prev \n",
    "        col_prev = [(df_trends_stocks[company])[col][i+1] for i in range(len((df_trends_stocks[company])) - 1)]\n",
    "        col_prev.append(0) # Append this so we can have 0 padding\n",
    "        df_all_data[col+'_prev'] = col_prev\n",
    "        \n",
    "        col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_trends_stocks[company])\n",
    "        \n",
    "        (df_trends_stocks[company])[col+'_movingAvg'] = col_movingAvg\n",
    "        (df_trends_stocks[company])[col+'_stdev'] = col_stdev\n",
    "    # Reverse index order\n",
    "    df_trends_stocks[company] = df_trends_stocks[company].iloc[::-1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LASSO Regression Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for LASSO Regression\n",
    "def getBestAlphaLASSORegression(y_col, parameter_cols, df_all_data_train):\n",
    "    split = int(df_all_data_train.shape[0]/2)\n",
    "    df_all_data_test = df_all_data_train[split:]\n",
    "    df_all_data_train = df_all_data_train[:split]\n",
    "    \n",
    "    X = df_all_data_train[parameter_cols]\n",
    "    y = df_all_data_train[y_col]\n",
    "    alpha = []\n",
    "    MSE_train = []\n",
    "    MSE_test = []\n",
    "    for i in range(90, 10000, 10):\n",
    "        clf = linear_model.Lasso(alpha=i)\n",
    "        clf.fit(X, y) \n",
    "        alpha.append(i)\n",
    "        MSE_train.append(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col]))\n",
    "        MSE_test.append(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col]))\n",
    "\n",
    "    bestAlpha = alpha[MSE_test.index(min(MSE_test))]\n",
    "    \n",
    "    print(\"alpha: \"+str(bestAlpha))\n",
    "    print(\"Training error = \"+str(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col])))\n",
    "    print(\"Testing error = \"+str(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col])))\n",
    "    print()\n",
    "    return bestAlpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions For Plotting LASSO Regression\n",
    "def plotLASSO(company, alpha, label, predictors, df): \n",
    "    # Separate Data\n",
    "    split = int(df.shape[0]/2)\n",
    "    df_train = df[:split]\n",
    "    df_test = df[split:]\n",
    "    X_train = df_train[predictors]\n",
    "    Y_train = df_train[label]\n",
    "    X_test = df_test[predictors]\n",
    "    Y_test = df_test[label]\n",
    "    Y_labels = df[label]\n",
    "    # Initialize Model w/ Optimal Alpha\n",
    "    clf = linear_model.Lasso(alpha=alpha)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    param_dict = dict(zip(clf.coef_, predictors))\n",
    "    print(\"Parameter Estimates w/ LASSO : \",param_dict)\n",
    "    # Make Predictions using optimal alpha value\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    # Plot test and train predictions against true labels\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.plot(range(split), y_pred_train, color='r')\n",
    "    ax1.plot(range(split, len(Y_labels)),y_pred_test, color='b')\n",
    "    ax1.plot(range(len(Y_labels)),Y_labels, color='g')\n",
    "    ax1.set_xlabel('Time in Hours')\n",
    "    ax1.set_ylabel(label)\n",
    "    ax1.set_title(label + ' Predictions with LASSO Regression for '+ company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run regression and view dropped features for each company**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnsAll(company, label): \n",
    "    cols = df_trends_stocks[company].columns\n",
    "    cols = list(cols)\n",
    "    cols.remove('times')\n",
    "    cols.remove('index')\n",
    "    cols.remove('date')\n",
    "    cols.remove(label)\n",
    "    return cols\n",
    "\n",
    "def columnsTrends(company, label): \n",
    "    cols = [x for x in list(df_trends_stocks[company].columns) if company in x]\n",
    "    return cols\n",
    "\n",
    "def columnsAverage(company, label): \n",
    "    cols = [x for x in list(df_trends_stocks[company].columns) if company not in x]\n",
    "    cols.remove(label)\n",
    "    cols.remove('times')\n",
    "    cols.remove('index')\n",
    "    cols.remove('date')\n",
    "    cols.remove('open')\n",
    "    cols.remove('volume')\n",
    "    cols.remove('high')\n",
    "    cols.remove('low')\n",
    "    cols.remove('close')\n",
    "    cols.remove('profit')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions w/ All Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keys = ['All Predictors ', 'Just Trends ','Just Stock Data']\n",
    "MSE = {key: None for key in keys}\n",
    "for company in companies: \n",
    "    # Prepare column list\n",
    "    cols = columnsAll(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha = getBestAlphaLASSORegression('mid',cols,df_trends_stocks[company])\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_trends_stocks[company])\n",
    "    # Plot MSE train and test for LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions for Just Trends Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for company in companies: \n",
    "    # Prepare column list\n",
    "    cols = columnsTrends(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha = getBestAlphaLASSORegression('mid',cols,df_trends_stocks[company])\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_trends_stocks[company])\n",
    "    # Plot MSE train and test for LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Predictions for Just Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies: \n",
    "    # Prepare column list\n",
    "    cols = columnsAverage(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha = getBestAlphaLASSORegression('mid',cols,df_trends_stocks[company])\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_trends_stocks[company])\n",
    "    # Plot MSE train and test for LASSO Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
