{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cogs 109: Modeling and Data Analysis\n",
    "## Final project guidelines, 2019\n",
    "\n",
    "Work in teams of at least 2 and no more than 4 students. Every student in the group will be expected to contribute substantially to the final product(s), and all students should be able to understand and explain all aspects of the project when you present your work in the final symposium.\n",
    "\n",
    "Your project should. \n",
    "- Identify a real problem, challenge or scientific question which could benefit from data analysis and modeling. Your final report must explain why the question is interesting or important. \n",
    "- Identify a relevant data set. You should learn about how the data was collected and be able to explain key features of the data, for example: How many observations? What are the noise sources? What are the relevant predictors?\n",
    "Identify at least one relevant data analysis approach, choosing from the methods covered in the course (linear or nonlinear regression, classification, clustering, PCA, etc.). Explain why this analysis approach is appropriate for addressing your question.\n",
    "- Identify and explain one or more hypotheses or initial expectation that you will test using the data.\n",
    "- Model selection: You should compare and contrast multiple different models (at least 2, but usually more). Your comparison should make use of cross-validation, bootstrap sampling, regularization, and/or other relevant techniques. For example, you might compare K-Nearest Neighbors classification for a range of k values (k=1,2,…,50), and select the k value that provides the lowest test set (cross-validation) error.\n",
    "- Model estimation: Implement your data analysis and present the results using a combination of data visualizations (box plots, scatter plots), statistical analyses and models.\n",
    "- Present your conclusions and outlook for next steps/future directions.\n",
    "\n",
    "The final product will be a written report, 5-10 pages in length. In addition, you will create a poster explaining your project to be presented in a symposium session on the last day of class. We will provide more information about the final paper and poster in a few weeks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written report:\n",
    "Your final report must include the following sections (use these headings).\n",
    "- Introduction. \n",
    "    - Define the real problem and explain its motivation\n",
    "    - Identify the dataset you will use and explain its key characteristics.\n",
    "    - Explain at least one hypothesis that you will test.\n",
    "- Methods. Identify the data analysis approach you will use and explain the rationale/motivation for your choice of this approach.\n",
    "- Results\n",
    "    - Model selection. You MUST compare at least 2 models, using cross-validation, regularization, and/or other relevant techniques.\n",
    "    - Model estimation. What are the final parameter estimates? What is the final accuracy of the model’s predictions?\n",
    "    - Conclusions and discussion. What can you conclude about your hypothesis? (Note that negative or ambiguous results are perfectly acceptable, you just need to explain what you found.) What are some potential implications/next steps for researchers interested in this topic?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy import linalg\n",
    "from sklearn.linear_model import Ridge\n",
    "from pytrends.request import TrendReq\n",
    "from pytrends import dailydata\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define company variables\n",
    "companies = ['tesla', 'facebook', 'microsoft', 'amazon', 'google', 'uber', 'lyft', 'apple', 'snap']\n",
    "key_terms = ['report', 'good', 'bad', 'up', 'down', 'stock']\n",
    "company_symbol = ['TSLA', 'FB', 'MSFT', 'AMZN', 'GOOGL', 'UBER', 'LYFT', 'AAPL', 'SNAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Key Words List for Pytrends\n",
    "kw_list = []\n",
    "for c_name in companies:\n",
    "    for k in key_terms:\n",
    "        kw_list.append(c_name + \" \" + k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Hourly Data from Pytrends "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla report\n",
      "tesla good\n",
      "tesla bad\n",
      "tesla up\n",
      "tesla down\n",
      "tesla stock\n",
      "facebook report\n",
      "facebook good\n",
      "facebook bad\n",
      "facebook up\n",
      "facebook down\n",
      "facebook stock\n",
      "microsoft report\n",
      "microsoft good\n",
      "microsoft bad\n",
      "microsoft up\n",
      "microsoft down\n",
      "microsoft stock\n",
      "amazon report\n",
      "amazon good\n",
      "amazon bad\n",
      "amazon up\n",
      "amazon down\n",
      "amazon stock\n",
      "google report\n",
      "google good\n",
      "google bad\n",
      "google up\n",
      "google down\n",
      "google stock\n",
      "uber report\n",
      "uber good\n",
      "uber bad\n",
      "uber up\n",
      "uber down\n",
      "uber stock\n",
      "lyft report\n",
      "lyft good\n",
      "lyft bad\n",
      "lyft up\n",
      "lyft down\n",
      "lyft stock\n",
      "apple report\n",
      "apple good\n",
      "apple bad\n",
      "apple up\n",
      "apple down\n",
      "apple stock\n",
      "snap report\n",
      "snap good\n",
      "snap bad\n",
      "snap up\n",
      "snap down\n",
      "snap stock\n"
     ]
    }
   ],
   "source": [
    "# Get Hourly trends data from pytrends\n",
    "df = pd.DataFrame()\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "for kw in kw_list:\n",
    "    print(kw)\n",
    "    df_temp = pytrends.get_historical_interest([kw], year_start=2019, month_start=11, day_start=18, hour_start=0, year_end=2019, month_end=11, day_end=22, hour_end=23,sleep=30, cat=0, geo='', gprop='')\n",
    "    if 'isPartial' in df_temp.columns: \n",
    "        df_temp = df_temp.drop(['isPartial'], axis=1)\n",
    "    if df.empty:\n",
    "        df = df_temp\n",
    "    else:\n",
    "        df = df.join(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tesla report</th>\n",
       "      <th>tesla good</th>\n",
       "      <th>tesla bad</th>\n",
       "      <th>tesla up</th>\n",
       "      <th>tesla down</th>\n",
       "      <th>tesla stock</th>\n",
       "      <th>facebook report</th>\n",
       "      <th>facebook good</th>\n",
       "      <th>facebook bad</th>\n",
       "      <th>facebook up</th>\n",
       "      <th>...</th>\n",
       "      <th>apple bad</th>\n",
       "      <th>apple up</th>\n",
       "      <th>apple down</th>\n",
       "      <th>apple stock</th>\n",
       "      <th>snap report</th>\n",
       "      <th>snap good</th>\n",
       "      <th>snap bad</th>\n",
       "      <th>snap up</th>\n",
       "      <th>snap down</th>\n",
       "      <th>snap stock</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-22 19:00:00</th>\n",
       "      <td>43</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>73</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>66</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 20:00:00</th>\n",
       "      <td>31</td>\n",
       "      <td>70</td>\n",
       "      <td>74</td>\n",
       "      <td>99</td>\n",
       "      <td>87</td>\n",
       "      <td>68</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>47</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>43</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 21:00:00</th>\n",
       "      <td>35</td>\n",
       "      <td>68</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 22:00:00</th>\n",
       "      <td>36</td>\n",
       "      <td>85</td>\n",
       "      <td>99</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>59</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>54</td>\n",
       "      <td>68</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "      <td>66</td>\n",
       "      <td>51</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-22 23:00:00</th>\n",
       "      <td>31</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>93</td>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>87</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     tesla report  tesla good  tesla bad  tesla up  \\\n",
       "date                                                                 \n",
       "2019-11-22 19:00:00            43          92         90       100   \n",
       "2019-11-22 20:00:00            31          70         74        99   \n",
       "2019-11-22 21:00:00            35          68        100        93   \n",
       "2019-11-22 22:00:00            36          85         99        89   \n",
       "2019-11-22 23:00:00            31         100         82        86   \n",
       "\n",
       "                     tesla down  tesla stock  facebook report  facebook good  \\\n",
       "date                                                                           \n",
       "2019-11-22 19:00:00          80           73               22             27   \n",
       "2019-11-22 20:00:00          87           68               24             28   \n",
       "2019-11-22 21:00:00          89           62               25             31   \n",
       "2019-11-22 22:00:00          77           59               27             30   \n",
       "2019-11-22 23:00:00          93           55               28             32   \n",
       "\n",
       "                     facebook bad  facebook up  ...  apple bad  apple up  \\\n",
       "date                                            ...                        \n",
       "2019-11-22 19:00:00            30           27  ...         36        48   \n",
       "2019-11-22 20:00:00            27           27  ...         33        47   \n",
       "2019-11-22 21:00:00            27           29  ...         34        50   \n",
       "2019-11-22 22:00:00            25           28  ...         35        54   \n",
       "2019-11-22 23:00:00            26           30  ...         41        57   \n",
       "\n",
       "                     apple down  apple stock  snap report  snap good  \\\n",
       "date                                                                   \n",
       "2019-11-22 19:00:00          70           27           15         34   \n",
       "2019-11-22 20:00:00          81           26           14         31   \n",
       "2019-11-22 21:00:00          72           26           15         34   \n",
       "2019-11-22 22:00:00          68           21           16         35   \n",
       "2019-11-22 23:00:00          87           17           24         23   \n",
       "\n",
       "                     snap bad  snap up  snap down  snap stock  \n",
       "date                                                           \n",
       "2019-11-22 19:00:00        50       43         66          32  \n",
       "2019-11-22 20:00:00        37       43         56          29  \n",
       "2019-11-22 21:00:00        36       47         38          37  \n",
       "2019-11-22 22:00:00        41       66         51          26  \n",
       "2019-11-22 23:00:00        40       58         33          19  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(df.head())\n",
    "#print(df.shape)\n",
    "#print(df.index)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worldTradingData_APIKey = ''\n",
    "# def getWorldTradingData_Intraday1min(symbol, days=1, interval=1) :\n",
    "#     # limits on the inputs https://www.worldtradingdata.com/documentation#stock-and-index-intraday\n",
    "#     link = \"https://intraday.worldtradingdata.com/api/v1/intraday?symbol={}&range={}&interval={}&api_token={}\"\\\n",
    "#         .format(symbol, days, interval, worldTradingData_APIKey)\n",
    "#     request = requests.get(link)\n",
    "#     data = json.loads(request.text)\n",
    "#     if 'intraday' not in data:\n",
    "#         return pd.DataFrame()\n",
    "#     stock_data = json.dumps(data[\"intraday\"])\n",
    "#     df = pd.read_json(stock_data).transpose()\n",
    "#     cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "#     df = df[cols]\n",
    "#     df.reset_index(level=0, inplace=True)\n",
    "#     df.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting data from World Tradiing Data\n",
    "# df_stocks = {}\n",
    "# for s in company_symbol:\n",
    "#     print(s)\n",
    "#     res = getWorldTradingData_Intraday1min(s)\n",
    "#     while res.empty:\n",
    "#         time.sleep(10)\n",
    "#         res = getWorldTradingData_Intraday1min(s)\n",
    "#     df_stocks[s] = getWorldTradingData_Intraday1min(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Stock Data from Alpha Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather Stock Data for each company and return dataframe \n",
    "ts = 'TIME_SERIES_INTRADAY'#'TIME_SERIES_DAILY'\n",
    "interval = '60min'\n",
    "api_key = '' \n",
    "outputsize = 'full' # compact= 100 results, full= all data (5 days?)\n",
    "def getIntraday1minDF(symbol): \n",
    "    link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "        .format(ts, symbol, interval, api_key, outputsize)\n",
    "    request = requests.get(link)\n",
    "    data = json.loads(request.text)\n",
    "    if \"Time Series (60min)\" not in data:\n",
    "        print(\"data limit reached\")\n",
    "        return pd.DataFrame()\n",
    "    stock_data = json.dumps(data[\"Time Series (60min)\"])\n",
    "    df = pd.read_json(stock_data).transpose()\n",
    "    cols = ['1. open', '2. high', '3. low', '4. close', '5. volume']\n",
    "    df = df[cols]\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TSLA\n",
      "FB\n",
      "MSFT\n",
      "AMZN\n",
      "GOOGL\n",
      "UBER\n",
      "data limit reached\n",
      "data limit reached\n",
      "data limit reached\n",
      "data limit reached\n",
      "data limit reached\n",
      "LYFT\n",
      "AAPL\n",
      "SNAP\n"
     ]
    }
   ],
   "source": [
    "# Gather stock data for each individual company\n",
    "df_stocks = {}\n",
    "for s in company_symbol:\n",
    "    print(s)\n",
    "    res = getIntraday1minDF(s)\n",
    "    # data limit reached\n",
    "    while res.empty:\n",
    "        time.sleep(10)\n",
    "        res = getIntraday1minDF(s)\n",
    "    # add stock information to dictionary\n",
    "    df_stocks[s] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>2019-09-06 13:30:00</td>\n",
       "      <td>229.0136</td>\n",
       "      <td>229.6400</td>\n",
       "      <td>228.5000</td>\n",
       "      <td>228.6000</td>\n",
       "      <td>379831.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2019-09-06 12:30:00</td>\n",
       "      <td>228.7685</td>\n",
       "      <td>229.5429</td>\n",
       "      <td>227.9234</td>\n",
       "      <td>229.0384</td>\n",
       "      <td>345214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>2019-09-06 11:30:00</td>\n",
       "      <td>227.6145</td>\n",
       "      <td>229.5105</td>\n",
       "      <td>227.5790</td>\n",
       "      <td>228.7695</td>\n",
       "      <td>514473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2019-09-06 10:30:00</td>\n",
       "      <td>226.7260</td>\n",
       "      <td>228.0207</td>\n",
       "      <td>226.5193</td>\n",
       "      <td>227.5410</td>\n",
       "      <td>579288.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2019-09-06 09:30:00</td>\n",
       "      <td>227.0072</td>\n",
       "      <td>229.0845</td>\n",
       "      <td>225.3909</td>\n",
       "      <td>226.7013</td>\n",
       "      <td>1511877.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  times      open      high       low     close     volume\n",
       "412 2019-09-06 13:30:00  229.0136  229.6400  228.5000  228.6000   379831.0\n",
       "413 2019-09-06 12:30:00  228.7685  229.5429  227.9234  229.0384   345214.0\n",
       "414 2019-09-06 11:30:00  227.6145  229.5105  227.5790  228.7695   514473.0\n",
       "415 2019-09-06 10:30:00  226.7260  228.0207  226.5193  227.5410   579288.0\n",
       "416 2019-09-06 09:30:00  227.0072  229.0845  225.3909  226.7013  1511877.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks['TSLA'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join Hourly Pytrends Data and Alpha Vantage Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla\n",
      "facebook\n",
      "microsoft\n",
      "amazon\n",
      "google\n",
      "uber\n",
      "lyft\n",
      "apple\n",
      "snap\n"
     ]
    }
   ],
   "source": [
    "# join Google Trends Data with Stock Market Data\n",
    "df_trends_stocks = {}\n",
    "def cleanAndJoinData():\n",
    "    for s,c in zip(company_symbol, companies):\n",
    "        print(c)\n",
    "        company_names = [x for x in list(df.columns.values) if c in x]\n",
    "        df_temp_trends = df[company_names]\n",
    "        \n",
    "        # line up indexes \n",
    "        stock_times = list(df_stocks[s].times)\n",
    "        trends_times = list(df_temp_trends.index)\n",
    "        joint_times = list(set(stock_times) & set(trends_times)) \n",
    "        \n",
    "        \n",
    "        df_temp_stocks = df_stocks[s].loc[df_stocks[s]['times'].isin(joint_times)]\n",
    "        df_temp_stocks = df_temp_stocks.reset_index()\n",
    "        df_temp_stocks = df_temp_stocks.iloc[::-1]\n",
    "        df_temp_trends = df_temp_trends.loc[df_temp_trends.index.isin(joint_times)]\n",
    "        df_temp_trends = df_temp_trends.reset_index()\n",
    "        df_temp_trends.columns = ['_'.join(x.split()) for x in list(df_temp_trends.columns) if len(x) > 1]\n",
    "        df_trends_stocks[c] = df_temp_stocks.join(df_temp_trends)\n",
    "cleanAndJoinData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [index, times, open, high, low, close, volume, date, tesla_report, tesla_good, tesla_bad, tesla_up, tesla_down, tesla_stock]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#check this is populated\n",
    "print(df_trends_stocks['tesla'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>times</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>date</th>\n",
       "      <th>apple_report</th>\n",
       "      <th>apple_good</th>\n",
       "      <th>apple_bad</th>\n",
       "      <th>apple_up</th>\n",
       "      <th>apple_down</th>\n",
       "      <th>apple_stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, times, open, high, low, close, volume, date, apple_report, apple_good, apple_bad, apple_up, apple_down, apple_stock]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trends_stocks['apple'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Using Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Training and Testing Partitions\n",
    "train_size = 28\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "for c in companies:\n",
    "    train_temp = df_trends_stocks[c][:train_size]\n",
    "    test_temp = df_trends_stocks[c][train_size:]\n",
    "    train_data[c] = train_temp\n",
    "    test_data[c] = test_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to be between 0-1 \n",
    "def predictCompany(company_name, train_size):\n",
    "    df_temp = df_trends_stocks[company_name]\n",
    "    print(company_name)\n",
    "    # average price at opening and closing \n",
    "    df_temp['mid'] = (df_temp['high'] - df_temp['low']) / 2\n",
    "    cols = [company_name+'_'+ x for x in key_terms]\n",
    "    # scale data to be between 0-1 including average\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    data_set_scaled = sc.fit_transform(df_temp[cols+['mid']])\n",
    "    \n",
    "    #split training data \n",
    "    train = data_set_scaled[:train_size, :]\n",
    "    test = data_set_scaled[train_size:, :]\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    \n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(train_size, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "    #train model\n",
    "    history = model.fit(train_X, train_y, epochs=500, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "    return history, model, train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE train/test\n",
    "def plotHistory(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "#plotHistory(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test and training set predictions over true data\n",
    "def plotPrediction(company, train_size, model, train_X, train_y, test_X, test_y):\n",
    "    plt.plot(range(len(train_y)+len(test_y)) , list(np.array(train_y))+list(np.array(test_y)), range(len(train_y)), model.predict(train_X), '-', range(len(train_y), len(train_y)+len(test_y)), model.predict(test_X), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Profit from previous day')\n",
    "    plt.title('FB Keras - Stock Market Mid per Day from 3 months until today')\n",
    "    plt.legend([\"True Data\",\"Training Data - Price change prediction\", \"Testing Data - Price change prediction\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Predictions for Each Company\n",
    "def plotCompanies(companies, train_size): \n",
    "    for company in companies: \n",
    "        # Fit model and predict for each company\n",
    "        history, model, train_X, train_y, test_X, test_y = predictCompany(company, train_size)\n",
    "        # Plot Prediction Against True Profit for Each Company\n",
    "        plotPrediction(company, train_size, model, train_X, train_y, test_X, test_y)\n",
    "        # Plot Error for Each Company\n",
    "        plotHistory(history)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tesla\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by MinMaxScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-992da1c20a29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotCompanies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompanies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-8f255210c28d>\u001b[0m in \u001b[0;36mplotCompanies\u001b[0;34m(companies, train_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcompany\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompanies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Fit model and predict for each company\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictCompany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Plot Prediction Against True Profit for Each Company\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mplotPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-42a19fc81cf6>\u001b[0m in \u001b[0;36mpredictCompany\u001b[0;34m(company_name, train_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# scale data to be between 0-1 including average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdata_set_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#split training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    351\u001b[0m         X = check_array(X, copy=self.copy,\n\u001b[1;32m    352\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m                         force_all_finite=\"allow-nan\")\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mdata_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    548\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 550\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 7)) while a minimum of 1 is required by MinMaxScaler."
     ]
    }
   ],
   "source": [
    "plotCompanies(companies, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history, model, train_X, train_y, test_X, test_y = predictCompany('google',28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotPrediction('google', train_size, model, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history, model, train_X, train_y, test_X, test_y = predictCompany('facebook',28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotPrediction('facebook', train_size, model, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history, model, train_X, train_y, test_X, test_y = predictCompany('microsoft',28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotPrediction('microsoft', train_size, model, train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history, model, train_X, train_y, test_X, test_y = predictCompany('apple',28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotPrediction('apple', train_size, model, train_X, train_y, test_X, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
