{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy import linalg\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from pytrends.request import TrendReq\n",
    "import os.path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/questions/50786266/writing-dictionary-of-dataframes-to-file\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def save_dict_df(dictex, keys_filename=\"keys.txt\", data_folder=\"stock_data\"):\n",
    "    for key, val in dictex.items():\n",
    "        val.to_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)))\n",
    "\n",
    "    with open(keys_filename, \"w\") as f: #saving keys to file\n",
    "        f.write(str(list(dictex.keys())))\n",
    "\n",
    "def load_dict_df(keys_filename=\"keys.txt\", data_folder=\"stock_data\"):\n",
    "    \"\"\"Reading data from keys\"\"\"\n",
    "    with open(keys_filename, \"r\") as f:\n",
    "        keys = eval(f.read())\n",
    "\n",
    "    dictex = {}    \n",
    "    for key in keys:\n",
    "        dictex[key] = pd.read_csv(\"./\"+data_folder+\"/data_{}.csv\".format(str(key)), index_col=0)\n",
    "\n",
    "    return dictex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['tesla', 'facebook', 'microsoft', 'amazon', 'google', 'uber', 'lyft', 'apple', 'snap']\n",
    "key_terms = ['report', 'good', 'bad', 'up', 'down', 'stock']\n",
    "company_symbol = ['TSLA', 'FB', 'MSFT', 'AMZN', 'GOOGL', 'UBER', 'LYFT', 'AAPL', 'SNAP']\n",
    "stock_columns = ['open', 'high', 'low', 'close', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create kw_list \n",
    "kw_list = []\n",
    "for c_name in companies:\n",
    "    for k in key_terms:\n",
    "        kw_list.append(c_name + \" \" + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 3-month ago trend data. May need to run a couple times to make sure it doesn't time out. \n",
    "def getTrendDataDF(kw_list, pull_data=False, dates='today 3-m', pytrends_df_filename=\"pytrends.csv\"):\n",
    "    # Retrieve the cached trend data\n",
    "    if not pull_data and os.path.isfile(pytrends_df_filename):\n",
    "        df = pd.read_csv(pytrends_df_filename, index_col=\"date\")\n",
    "        \n",
    "    else: # Construct the dataframe by making pytrends calls\n",
    "        df = pd.DataFrame()\n",
    "        data = {}\n",
    "        #print(df.empty)\n",
    "        pytrends = TrendReq(hl='en-US', tz=360)\n",
    "        for kw in kw_list:\n",
    "            pytrends.build_payload([kw], cat=0, timeframe=dates, geo='', gprop='')\n",
    "            df_temp = pytrends.interest_over_time()\n",
    "            df_temp = df_temp.drop(['isPartial'], axis=1)\n",
    "            # print(kw)\n",
    "            data[kw] = df_temp\n",
    "        for kw in kw_list:\n",
    "            if df.empty:\n",
    "                df = data[kw]\n",
    "            else:\n",
    "                df = df.join(data[kw])\n",
    "        df.to_csv(pytrends_df_filename)\n",
    "    #reverse df rows\n",
    "    df = df.iloc[::-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Stock Daily info for past 100 days\n",
    "def getDailyStockInfoDict(company_symbol, pull_data=False, stock_df_filename=\"stock_keys.txt\"):\n",
    "    if not pull_data and os.path.isfile(stock_df_filename):\n",
    "        dict_stocks = load_dict_df(keys_filename=stock_df_filename);\n",
    "    else :\n",
    "        ts = 'TIME_SERIES_DAILY'\n",
    "        api_key = ''\n",
    "        outputsize = 'compact'\n",
    "        dict_stocks = {}\n",
    "        for i, symbol in enumerate(company_symbol):\n",
    "            link = 'https://www.alphavantage.co/query?function={}&symbol={}&apikey={}&outputsize={}'\\\n",
    "                    .format(ts, symbol, api_key, outputsize)\n",
    "            r = requests.get(link)\n",
    "            data = json.loads(r.text)\n",
    "            # API only give you 5 requests per 5 mins, so break out if response is not what is expected.\n",
    "            while \"Time Series (Daily)\" not in data:\n",
    "                print('...sleeping...')\n",
    "                time.sleep(70)\n",
    "                link = 'https://www.alphavantage.co/query?function={}&symbol={}&apikey={}&outputsize={}'\\\n",
    "                    .format(ts, symbol, api_key, outputsize)\n",
    "                r = requests.get(link)\n",
    "                data = json.loads(r.text)\n",
    "            stock_data_per_day = json.dumps(data[\"Time Series (Daily)\"])\n",
    "            df_temp = pd.read_json(stock_data_per_day).transpose()\n",
    "            df_temp.reset_index(level=0, inplace=True)\n",
    "            df_temp.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "            dict_stocks[companies[i]] = df_temp\n",
    "        save_dict_df(dict_stocks, keys_filename=stock_df_filename)\n",
    "    return dict_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrends(company_name, df_trends):\n",
    "    # Filters the trends\n",
    "    company_keywords =  [x for x in list(df_trends.columns.values) if company_name in x]\n",
    "    return df_trends[company_keywords].copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJointTimes(df_stock, df_trends): \n",
    "    stock_times = df_stock['times']\n",
    "    trends_times = list(df_trends.index)\n",
    "    return list(set(stock_times) & set(trends_times)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOverlapDateData(company_name, dict_stocks, df_trends): \n",
    "    new_df_trends = getTrends(company_name, df_trends)\n",
    "    \n",
    "    joint_times = getJointTimes(dict_stocks[company_name], new_df_trends)\n",
    "    new_df_stocks = dict_stocks[company_name].loc[dict_stocks[company_name]['times'].isin(joint_times)]\n",
    "    new_df_stocks = new_df_stocks.reset_index() \n",
    "    \n",
    "    new_df_trends = new_df_trends.loc[new_df_trends.index.isin(joint_times)]\n",
    "    new_df_trends = new_df_trends.reset_index()\n",
    "    new_df_trends.columns = ['_'.join(x.split()) for x in list(new_df_trends.columns) if len(x) > 1]\n",
    "    df_all_data = new_df_stocks.join(new_df_trends)\n",
    "    return df_all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def trainMultipleRegression(y_col, parameter_cols, training_data): \n",
    "    formula = y_col + ' ~ 1'\n",
    "    for i in parameter_cols: \n",
    "        formula = formula + \" + \" + i\n",
    "\n",
    "    result = sm.formula.ols(formula=formula, data=training_data).fit()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMultipleRegressionAndGetMSE(company, result, y_col, cols, all_data, training_data, testing_data):\n",
    "    y_pred = result.predict()\n",
    "    plt.plot(range(len(all_data[y_col])) , all_data[y_col])\n",
    "    plt.plot(range(50), result.predict(training_data[cols]), '-')\n",
    "    plt.plot(range(50, len(df_all_data[y_col])), result.predict(testing_data[cols]), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Output $ amount')\n",
    "    plt.title(company + ' Multiple Regression: ' + str(y_col))\n",
    "    plt.legend([\"True Data\",\"Training Data - Price change prediction\", \"Testing Data - Price change prediction\"])\n",
    "    plt.show()\n",
    "    \n",
    "    MSE = mean_squared_error(result.predict(testing_data[cols]), testing_data[y_col]) / (np.mean(testing_data[y_col]) * np.std(testing_data[y_col]))\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestAlphaRidgeRegression(y_col, parameter_cols, df_all_data_train):\n",
    "    df_all_data_test = df_all_data_train[40:]\n",
    "    df_all_data_train = df_all_data_train[:40]\n",
    "    \n",
    "    X = df_all_data_train[parameter_cols]\n",
    "    y = df_all_data_train[y_col]\n",
    "    alpha = []\n",
    "    MSE_train = []\n",
    "    MSE_test = []\n",
    "    for i in range(90, 2000, 10):\n",
    "        clf = Ridge(alpha=i)\n",
    "        clf.fit(X, y) \n",
    "        alpha.append(i)\n",
    "        MSE_train.append(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col]))\n",
    "        MSE_test.append(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col]))\n",
    "\n",
    "    bestAlpha = alpha[MSE_test.index(min(MSE_test))]\n",
    "    \n",
    "    print(\"alpha: \"+str(bestAlpha))\n",
    "    print(\"Training error = \"+str(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col])))\n",
    "    print(\"Testing error = \"+str(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col])))\n",
    "    print()\n",
    "    return bestAlpha, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge regression\n",
    "\n",
    "def trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, parameter_cols, df_all_data_train, df_all_data_test) : \n",
    "    bestAlpha, clf = getBestAlphaRidgeRegression(y_col, parameter_cols, df_all_data_train)\n",
    "    \n",
    "    X = df_all_data_train[parameter_cols]\n",
    "    y = df_all_data_train[y_col]\n",
    "    \n",
    "    #plot data with training and test data\n",
    "    clf = Ridge(alpha=bestAlpha)\n",
    "    clf.fit(X, y) \n",
    "    plt.plot(range(len(df_all_data[y_col])) , df_all_data[y_col])\n",
    "    plt.plot(range(50), clf.predict(df_all_data_train[cols]), '-')\n",
    "    plt.plot(range(50, len(df_all_data[y_col])), clf.predict(df_all_data_test[cols]), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Output $ amount')\n",
    "    plt.title(company + ' Ridge Regression: ' + str(y_col))\n",
    "    plt.legend([\"True Data\",\"Training Data - Price change prediction\", \"Testing Data - Price change prediction\"])\n",
    "    plt.show()\n",
    "    \n",
    "    print(clf.get_params())\n",
    "    MSE = mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col]) / (np.mean(df_all_data_test[y_col]) * np.std(df_all_data_test[y_col]))\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovingAvgAndStdDev(col_name, num_days, df_all_data):\n",
    "    # Moving average and stdev past X days\n",
    "    col_movingAvg = []\n",
    "    col_stdev = []\n",
    "    \n",
    "    num_days_to_average = 10\n",
    "    for i in range(len(df_all_data)):\n",
    "        sum_to_avg = 0\n",
    "        nums = []\n",
    "        num_to_avg = min(num_days_to_average, len(df_all_data) - i) - 1\n",
    "        for j in range(1, num_to_avg):\n",
    "            sum_to_avg += df_all_data[col][i + j]\n",
    "            nums.append(df_all_data[col][i + j])\n",
    "        avg = sum_to_avg / (num_to_avg if num_to_avg > 0 else 1)\n",
    "        stdev = np.std((nums if nums else [0]))\n",
    "\n",
    "        col_movingAvg.append(avg)\n",
    "        col_stdev.append(stdev)\n",
    "    return col_movingAvg, col_stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllParamCols(df_all_data):\n",
    "    cols = list(df_all_data.columns)\n",
    "    cols.remove('profit')\n",
    "    cols.remove('open')\n",
    "    cols.remove('close')\n",
    "    cols.remove('high')\n",
    "    cols.remove('low')\n",
    "    cols.remove('times')\n",
    "    cols.remove('date')\n",
    "    cols.remove('index')\n",
    "    cols.remove('volume')\n",
    "    cols.remove('mid')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get trend data\n",
    "df_trends = getTrendDataDF(kw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock data\n",
    "dict_stocks = getDailyStockInfoDict(company_symbol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with all predictors, and only moving averages, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MSE_dict = {} # {\"company\":{\"multipleRegressionProfit\":value, \"multipleRegressionCost\":value, etc}}\n",
    "# Join data together, train various models\n",
    "for company in companies[:1]: \n",
    "    print(company)\n",
    "    MSE_dict[company] = {}\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    \n",
    "    \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data)\n",
    "    \n",
    "    # Include moving average, stdev, and prev. 10 days. \n",
    "    num_days_to_average = 10\n",
    "    col = 'profit'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "    df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "    df_all_data[col+'_stdev'] = col_stdev\n",
    "    col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_all_data[col+'_prev'] = col_prev\n",
    "    \n",
    "    col = 'mid'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "    df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "    df_all_data[col+'_stdev'] = col_stdev\n",
    "    col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_all_data[col+'_prev'] = col_prev\n",
    "    \n",
    "    col = 'volume'\n",
    "    col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "    df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "    df_all_data[col+'_stdev'] = col_stdev\n",
    "    col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "    col_prev.append(0) # Append this so we can have 0 padding\n",
    "    df_all_data[col+'_prev'] = col_prev\n",
    "    \n",
    "    # Include movingAvg, stdev, and prev for all the Trends cols\n",
    "    for col in cols: \n",
    "        # Prev info\n",
    "        col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "        col_prev.append(0) # Append this so we can have 0 padding\n",
    "        df_all_data[col+'_prev'] = col_prev\n",
    "        \n",
    "        col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "        \n",
    "        df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "        df_all_data[col+'_stdev'] = col_stdev\n",
    "\n",
    "    \n",
    "    cols = getAllParamCols(df_all_data)\n",
    "        \n",
    "    # Reverse index order\n",
    "    df_all_data = df_all_data.iloc[::-1] \n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_all_data[:50]\n",
    "    df_all_data_test = df_all_data[50:]\n",
    "    \n",
    "    MSE_dict[company][\"MultipleRegression\"] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"] = {}\n",
    "    parameter_type = \"allPredictors\"\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type] = {}\n",
    "                         \n",
    "    # Multiple Regression, All Predictors\n",
    "    y_col='mid'\n",
    "    close_multiple_regression_res = trainMultipleRegression(y_col, cols, df_all_data_train)\n",
    "    print(close_multiple_regression_res.summary())\n",
    "    MSE = plotMultipleRegressionAndGetMSE(company, close_multiple_regression_res, y_col, cols, df_all_data, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    \n",
    "    # RIDGE REGRESSION REQUIRES STANDARDIZATION\n",
    "    # Standardize the input parameters\n",
    "    df_standardized_data = df_all_data.copy()\n",
    "\n",
    "    for col in cols: \n",
    "        df_standardized_data[col] = df_standardized_data[col] / np.std(df_standardized_data[col].values)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_standardized_data[:50]\n",
    "    df_all_data_test = df_standardized_data[50:]\n",
    "    \n",
    "    # Ridge Regression, All Predictors\n",
    "    MSE = trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, cols, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Predictions using only stock market data #### \n",
    "    # Remove any cols in col that has the company name in it. \n",
    "    print(\"No Trend Data\")\n",
    "    cols_noTrends = [col for col in cols if company not in col]\n",
    "    cols = cols_noTrends\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_all_data[:50]\n",
    "    df_all_data_test = df_all_data[50:]\n",
    "    \n",
    "    parameter_type = \"noTrend\"\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type] = {}\n",
    "    \n",
    "    # Multiple Regression\n",
    "    close_multiple_regression_res = trainMultipleRegression(y_col, cols, df_all_data_train)\n",
    "    print(close_multiple_regression_res.summary())\n",
    "    MSE = plotMultipleRegressionAndGetMSE(company, close_multiple_regression_res, y_col, cols, df_all_data, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    # Standardize the input parameters\n",
    "    df_standardized_data = df_all_data.copy()\n",
    "\n",
    "    for col in cols: \n",
    "        df_standardized_data[col] = df_standardized_data[col] / np.std(df_standardized_data[col].values)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_standardized_data[:50]\n",
    "    df_all_data_test = df_standardized_data[50:]\n",
    "    \n",
    "    # Ridge Regression\n",
    "    MSE = trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, cols, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting with only Google Trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Join data together, train various models\n",
    "for company in companies[:1]: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    \n",
    "    \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data)\n",
    "    \n",
    "    num_days_to_average = 10\n",
    "    for col in cols: \n",
    "        # Prev to today increment amount\n",
    "        col_prev = [df_all_data[col][i+1] for i in range(len(df_all_data) - 1)]\n",
    "        col_prev.append(0) # Append this so we can have 0 padding\n",
    "        df_all_data[col+'_prev'] = col_prev\n",
    "        \n",
    "        col_movingAvg, col_stdev = getMovingAvgAndStdDev(col, num_days_to_average, df_all_data)\n",
    "        \n",
    "        df_all_data[col+'_movingAvg'] = col_movingAvg\n",
    "        df_all_data[col+'_stdev'] = col_stdev\n",
    "\n",
    "    \n",
    "    cols = getAllParamCols(df_all_data)\n",
    "        \n",
    "    # Reverse index order\n",
    "    df_all_data = df_all_data.iloc[::-1] \n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_all_data[:50]\n",
    "    df_all_data_test = df_all_data[50:]\n",
    "    \n",
    "    \n",
    "    parameter_type=\"onlyTrends\"\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type] = {}\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type] = {}\n",
    "    y_col='mid'\n",
    "    \n",
    "    # Profit prediction: \n",
    "    close_multiple_regression_res = trainMultipleRegression(y_col, cols, df_all_data_train)\n",
    "    print(close_multiple_regression_res.summary())\n",
    "    MSE = plotMultipleRegressionAndGetMSE(company, close_multiple_regression_res, y_col, cols, df_all_data, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"MultipleRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    # Standardize the input parameters\n",
    "    df_standardized_data = df_all_data.copy()\n",
    "\n",
    "    for col in cols: \n",
    "        df_standardized_data[col] = df_standardized_data[col] / np.std(df_standardized_data[col].values)\n",
    "    \n",
    "    # Split into training and testing data\n",
    "    df_all_data_train = df_standardized_data[:50]\n",
    "    df_all_data_test = df_standardized_data[50:]\n",
    "    \n",
    "    \n",
    "    # Ridge Regression\n",
    "    MSE = trainAndPlotRidgeRegressionAndReturnMSE(company, y_col, cols, df_all_data_train, df_all_data_test)\n",
    "    MSE_dict[company][\"RidgeRegression\"][parameter_type][y_col] = MSE\n",
    "    print(\"MSE:\", MSE)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMSE(y_col, model):\n",
    "    for company in companies[:1]:\n",
    "        plt.plot([\"all predictors\", \"only trends\", \"no trends\"], [MSE_dict[company][model]['allPredictors'][y_col],  MSE_dict[company][model]['onlyTrends'][y_col], MSE_dict[company][model]['noTrend'][y_col]], label=company)\n",
    "\n",
    "    plt.xlabel(\"parameter types\")\n",
    "    plt.ylabel(\"MSE / mean stock price\")\n",
    "    plt.legend()\n",
    "    plt.title(model + \" \" + y_col);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"mid\"\n",
    "model = \"MultipleRegression\"\n",
    "plotMSE(y_col, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col = \"mid\"\n",
    "model = \"RidgeRegression\"\n",
    "plotMSE(y_col, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for LASSO Regression\n",
    "def getBestAlphaLASSORegression(y_col, parameter_cols, df_all_data_train):\n",
    "    split = int(df_all_data_train.shape[0]/2)\n",
    "    df_all_data_test = df_all_data_train[split:]\n",
    "    df_all_data_train = df_all_data_train[:split]\n",
    "    \n",
    "    X = df_all_data_train[parameter_cols]\n",
    "    y = df_all_data_train[y_col]\n",
    "    \n",
    "    alpha = []\n",
    "    MSE_train = []\n",
    "    MSE_test = []\n",
    "    for i in range(90, 10000, 10):\n",
    "        clf = Lasso(alpha=i)\n",
    "        clf.fit(X, y) \n",
    "        alpha.append(i)\n",
    "        MSE_train.append(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col]))\n",
    "        MSE_test.append(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col]))\n",
    "    \n",
    "    bestAlpha = alpha[MSE_test.index(min(MSE_test))]\n",
    "    clf = Lasso(alpha=bestAlpha)\n",
    "    clf.fit(X, y)\n",
    "    bestMSE = mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col])\n",
    "    print(\"alpha: \"+str(bestAlpha))\n",
    "    print(\"Training error = \"+str(mean_squared_error(clf.predict(df_all_data_train[cols]), df_all_data_train[y_col])))\n",
    "    print(\"Testing error = \"+str(mean_squared_error(clf.predict(df_all_data_test[cols]), df_all_data_test[y_col])))\n",
    "    print()\n",
    "    return bestAlpha, bestMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions For Plotting LASSO Regression\n",
    "def plotLASSO(company, alpha, label, predictors, df): \n",
    "    # Separate Data\n",
    "    split = int(df.shape[0]/2)\n",
    "    df_train = df[:split]\n",
    "    df_test = df[split:]\n",
    "    X_train = df_train[predictors]\n",
    "    Y_train = df_train[label]\n",
    "    X_test = df_test[predictors]\n",
    "    Y_test = df_test[label]\n",
    "    Y_labels = df[label]\n",
    "    # Initialize Model w/ Optimal Alpha\n",
    "    clf = Lasso(alpha=alpha)\n",
    "    clf.fit(X_train, Y_train) \n",
    "    df_temp = pd.DataFrame.from_dict(dict([(a,b) for a,b in sorted(zip(clf.coef_, predictors))]),orient='index')\n",
    "    # Make Predictions using optimal alpha value\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    # Plot test and train predictions against true labels\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.plot(range(split), y_pred_train, color='r')\n",
    "    ax1.plot(range(split, len(Y_labels)),y_pred_test, color='b')\n",
    "    ax1.plot(range(len(Y_labels)),Y_labels, color='g')\n",
    "    ax1.set_xlabel('Time in Hours')\n",
    "    ax1.set_ylabel(label)\n",
    "    ax1.set_title(label + ' Predictions with LASSO Regression for '+ company)\n",
    "    plt.legend([\"True Data\",\"Training Data - Price change prediction\", \"Testing Data - Price change prediction\"])\n",
    "    plt.show()\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnsAll(company, label): \n",
    "    cols = getOverlapDateData(company, dict_stocks, df_trends).columns\n",
    "    cols = list(cols)\n",
    "    cols.remove('times')\n",
    "    cols.remove('index')\n",
    "    cols.remove('date')\n",
    "    return cols\n",
    "\n",
    "def columnsTrends(company, label): \n",
    "    cols = [x for x in list(getOverlapDateData(company, dict_stocks, df_trends).columns) if company in x]\n",
    "    return cols\n",
    "\n",
    "def columnsAverage(company, label): \n",
    "    cols = [x for x in list(getOverlapDateData(company, dict_stocks, df_trends).columns) if company not in x]\n",
    "    cols.remove('times')\n",
    "    cols.remove('index')\n",
    "    cols.remove('date')\n",
    "    cols.remove('open')\n",
    "    cols.remove('volume')\n",
    "    cols.remove('high')\n",
    "    cols.remove('low')\n",
    "    cols.remove('close')\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Predictions w/ All Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['All Predictors', 'Only Trends','Only Stocks']\n",
    "MSE = {key: None for key in keys}\n",
    "MSE_companies = {company: MSE.copy() for company in companies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies[2:3]: \n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    df_all_data['mid'] = (df_all_data['high'] + df_all_data['low'])/2\n",
    "    print(company)\n",
    "    # Prepare column list\n",
    "    cols = columnsAll(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha, MSE_all = getBestAlphaLASSORegression('mid',cols,df_all_data)\n",
    "    # Plot Predictions by True Labels\n",
    "    df_coefficients = plotLASSO(company, alpha, 'mid', cols, df_all_data)\n",
    "    # Plot MSE for LASSO Regression\n",
    "    MSE_companies[company]['All Predictors']  = MSE_all\n",
    "    print(df_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies[2:3]: \n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    df_all_data['mid'] = (df_all_data['high'] + df_all_data['low'])/2\n",
    "    # Prepare column list\n",
    "    cols = columnsTrends(company, 'mid') \n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha, MSE_trends = getBestAlphaLASSORegression('mid',cols,df_all_data)\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_all_data)\n",
    "    # Plot MSE train and test for LASSO Regression\n",
    "    MSE_companies[company]['Only Trends']  = MSE_trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies[2:3]: \n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    df_all_data['mid'] = (df_all_data['high'] + df_all_data['low'])/2\n",
    "    # Prepare column list\n",
    "    cols = stock_columns\n",
    "    # Find best alpha for LASSO Regression\n",
    "    alpha, MSE_stock = getBestAlphaLASSORegression('mid',cols, df_all_data)\n",
    "    print(\"MSE: \",MSE_stock)\n",
    "    # Plot Predictions by True Labels\n",
    "    plotLASSO(company, alpha, 'mid', cols, df_all_data)\n",
    "    # Plot MSE train and test for LASSO Regression\n",
    "    MSE_companies[company]['Only Stocks']  = MSE_stock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow + Keras time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to be between 0-1 \n",
    "def predictCompany(df_temp, train_size, cols):\n",
    "    # scale data to be between 0-1 including average\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    data_set_scaled = sc.fit_transform(df_temp[cols+['mid']])\n",
    "    \n",
    "    #split training data \n",
    "    train = data_set_scaled[:train_size, :]\n",
    "    test = data_set_scaled[train_size:, :]\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    \n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(train_size, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "    #train model\n",
    "    history = model.fit(train_X, train_y, epochs=500, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "    return history, model, train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrediction(company, train_size, model, train_X, train_y, test_X, test_y):\n",
    "    plt.plot(range(len(train_y)+len(test_y)) , list(np.array(train_y))+list(np.array(test_y)), range(len(train_y)), model.predict(train_X), '-', range(len(train_y), len(train_y)+len(test_y)), model.predict(test_X), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Profit from previous day')\n",
    "    plt.title(company + ' - predicting stock market with Keras')\n",
    "    plt.legend([\"True Data\",\"Training Data\", \"Testing Data\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trends only!\n",
    "MSE_train_trends_only = []\n",
    "MSE_test_trends_only = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data)\n",
    "    \n",
    "    # Plotting only Google Trends data \n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(df_all_data, 50, cols)\n",
    "    plotHistory(history)\n",
    "    plotPrediction(company, 50, model, train_X, train_y, test_X, test_y)\n",
    "    MSE_train_trends_only.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_trends_only.append((company, mean_squared_error(model.predict(test_X), test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stock only!\n",
    "MSE_train_stock_only = []\n",
    "MSE_test_stock_only = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = stock_columns\n",
    "    \n",
    "    # Plotting only Google Trends data \n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(df_all_data, 50, cols)\n",
    "    plotHistory(history)\n",
    "    plotPrediction(company, 50, model, train_X, train_y, test_X, test_y)\n",
    "    MSE_train_stock_only.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_stock_only.append((company, mean_squared_error(model.predict(test_X), test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both trends and stock!\n",
    "MSE_train_both = []\n",
    "MSE_test_both = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    # Get specific company data\n",
    "    df_all_data = getOverlapDateData(company, dict_stocks, df_trends)  \n",
    "    # Add more data columns\n",
    "    df_all_data['profit'] = df_all_data['open']-df_all_data['close']\n",
    "    df_all_data['mid'] = (df_all_data['high']+df_all_data['low'])/2\n",
    "    \n",
    "    # Trends cols (everything except these cols that are removed)\n",
    "    cols = getAllParamCols(df_all_data) + stock_columns\n",
    "    \n",
    "    # Plotting only Google Trends data \n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(df_all_data, 50, cols)\n",
    "    plotHistory(history)\n",
    "    plotPrediction(company, 50, model, train_X, train_y, test_X, test_y)\n",
    "    MSE_train_both.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_both.append((company, mean_squared_error(model.predict(test_X), test_y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot MSE_train data points as scatter plots\n",
    "X = [x[0] for x in MSE_train_both]\n",
    "trends_only = [x[1] for x in MSE_train_trends_only]\n",
    "stock_only = [x[1] for x in MSE_train_stock_only]\n",
    "both = [x[1] for x in MSE_train_both]\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(X,trends_only, '.', X, stock_only, '^', X, both, '.')\n",
    "plt.xlabel('Companies')\n",
    "plt.ylabel('MSE Train')\n",
    "plt.title('MSE Train per company training on a Keras model')\n",
    "ax.legend(['trends only', 'stock_only', 'both'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot MSE_test data points as scatter plots\n",
    "X = [x[0] for x in MSE_test_both]\n",
    "trends_only = [x[1] for x in MSE_test_trends_only]\n",
    "stock_only = [x[1] for x in MSE_test_stock_only]\n",
    "both = [x[1] for x in MSE_test_both]\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(X,trends_only, '.', X, stock_only, '^', X, both, '.')\n",
    "plt.xlabel('Companies')\n",
    "plt.ylabel('MSE Test')\n",
    "plt.title('MSE Test per company training on a Keras model')\n",
    "ax.legend(['trends only', 'stock_only', 'both'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
