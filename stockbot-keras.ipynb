{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from scipy import linalg\n",
    "from sklearn.linear_model import Ridge\n",
    "from pytrends.request import TrendReq\n",
    "from pytrends import dailydata\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define company variables\n",
    "companies = ['tesla', 'facebook', 'microsoft', 'amazon', 'google', 'uber', 'lyft', 'apple', 'snap']\n",
    "key_terms = ['report', 'good', 'bad', 'up', 'down', 'stock']\n",
    "company_symbol = ['TSLA', 'FB', 'MSFT', 'AMZN', 'GOOGL', 'UBER', 'LYFT', 'AAPL', 'SNAP']\n",
    "stock_columns = ['open', 'high', 'low', 'close', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Key Words List for Pytrends\n",
    "kw_list = []\n",
    "for c_name in companies:\n",
    "    for k in key_terms:\n",
    "        kw_list.append(c_name + \" \" + k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Hourly trends data from pytrends\n",
    "# If there is a server 500 error, try changing the dates to this past week! \n",
    "df = pd.DataFrame()\n",
    "data = {}\n",
    "pytrends = TrendReq(hl='en-US', tz=360)\n",
    "for kw in kw_list:\n",
    "    print(kw)\n",
    "    df_temp = pytrends.get_historical_interest([kw], year_start=2019, month_start=11, day_start=25, hour_start=0, year_end=2019, month_end=11, day_end=29, hour_end=23)\n",
    "    if 'isPartial' in df_temp.columns: \n",
    "        df_temp = df_temp.drop(['isPartial'], axis=1)\n",
    "    data[kw] = df_temp\n",
    "for kw in kw_list:\n",
    "    if df.empty:\n",
    "        df = data[kw]\n",
    "    else:\n",
    "        df = df.join(data[kw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check on the data \n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.index)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worldTradingData_APIKey = ''\n",
    "# def getWorldTradingData_Intraday1min(symbol, days=1, interval=1) :\n",
    "#     # limits on the inputs https://www.worldtradingdata.com/documentation#stock-and-index-intraday\n",
    "#     link = \"https://intraday.worldtradingdata.com/api/v1/intraday?symbol={}&range={}&interval={}&api_token={}\"\\\n",
    "#         .format(symbol, days, interval, worldTradingData_APIKey)\n",
    "#     request = requests.get(link)\n",
    "#     data = json.loads(request.text)\n",
    "#     if 'intraday' not in data:\n",
    "#         return pd.DataFrame()\n",
    "#     stock_data = json.dumps(data[\"intraday\"])\n",
    "#     df = pd.read_json(stock_data).transpose()\n",
    "#     cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "#     df = df[cols]\n",
    "#     df.reset_index(level=0, inplace=True)\n",
    "#     df.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting data from World Trading Data\n",
    "# df_stocks = {}\n",
    "# for s in company_symbol:\n",
    "#     print(s)\n",
    "#     res = getWorldTradingData_Intraday1min(s)\n",
    "#     while res.empty:\n",
    "#         time.sleep(10)\n",
    "#         res = getWorldTradingData_Intraday1min(s)\n",
    "#     df_stocks[s] = getWorldTradingData_Intraday1min(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather Stock Data for each company and return dataframe \n",
    "ts = 'TIME_SERIES_INTRADAY'#'TIME_SERIES_DAILY'\n",
    "interval = '30min'\n",
    "api_key = '' \n",
    "outputsize = 'full' # compact= 100 results, full= all data (5 days?)\n",
    "def getIntraday1minDF(symbol): \n",
    "    link = 'https://www.alphavantage.co/query?function={}&symbol={}&interval={}&apikey={}&outputsize={}'\\\n",
    "        .format(ts, symbol, interval, api_key, outputsize)\n",
    "    request = requests.get(link)\n",
    "    data = json.loads(request.text)\n",
    "    if \"Time Series (30min)\" not in data:\n",
    "        print(\"data limit reached\")\n",
    "        return pd.DataFrame()\n",
    "    stock_data = json.dumps(data[\"Time Series (30min)\"])\n",
    "    df = pd.read_json(stock_data).transpose()\n",
    "    cols = ['1. open', '2. high', '3. low', '4. close', '5. volume']\n",
    "    df = df[cols]\n",
    "    df.reset_index(level=0, inplace=True)\n",
    "    df.columns = ['times', 'open', 'high', 'low', 'close', 'volume']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gather stock data for each individual company\n",
    "df_stocks = {}\n",
    "for s in company_symbol:\n",
    "    print(s)\n",
    "    res = getIntraday1minDF(s)\n",
    "    # data limit reached\n",
    "    while res.empty:\n",
    "        time.sleep(10)\n",
    "        res = getIntraday1minDF(s)\n",
    "    # add stock information to dictionary\n",
    "    df_stocks[s] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stocks['TSLA'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join Google Trends Data with Stock Market Data\n",
    "df_trends_stocks = {}\n",
    "def cleanAndJoinData():\n",
    "    for s,c in zip(company_symbol, companies):\n",
    "        print(c)\n",
    "        company_names = [x for x in list(df.columns.values) if c in x]\n",
    "        df_temp_trends = df[company_names]\n",
    "        \n",
    "        # line up indexes \n",
    "        stock_times = list(df_stocks[s].times)\n",
    "        trends_times = list(df_temp_trends.index)\n",
    "        joint_times = list(set(stock_times) & set(trends_times)) \n",
    "        \n",
    "        print(joint_times)\n",
    "        df_temp_stocks = df_stocks[s].loc[df_stocks[s]['times'].isin(joint_times)]\n",
    "        df_temp_stocks = df_temp_stocks.reset_index()\n",
    "        df_temp_stocks = df_temp_stocks.iloc[::-1]\n",
    "        df_temp_trends = df_temp_trends.loc[df_temp_trends.index.isin(joint_times)]\n",
    "        df_temp_trends = df_temp_trends.reset_index()\n",
    "        df_temp_trends.columns = ['_'.join(x.split()) for x in list(df_temp_trends.columns) if len(x) > 1]\n",
    "        df_trends_stocks[c] = df_temp_stocks.join(df_temp_trends)\n",
    "cleanAndJoinData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check that data is merged correctly \n",
    "df_trends_stocks['tesla'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Training and Testing Partitions\n",
    "train_size = int(len(df_trends_stocks[list(df_trends_stocks.keys())[0]])*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to be between 0-1 \n",
    "def predictCompany(company_name, train_size, cols):\n",
    "    df_temp = df_trends_stocks[company_name]\n",
    "    # average price at opening and closing \n",
    "    df_temp['mid'] = (df_temp['high'] - df_temp['low']) / 2\n",
    "    # scale data to be between 0-1 including average\n",
    "    sc = MinMaxScaler(feature_range = (0, 1))\n",
    "    data_set_scaled = sc.fit_transform(df_temp[cols+['mid']])\n",
    "    \n",
    "    #split training data \n",
    "    train = data_set_scaled[:train_size, :]\n",
    "    test = data_set_scaled[train_size:, :]\n",
    "    train_X, train_y = train[:, :-1], train[:, -1]\n",
    "    test_X, test_y = test[:, :-1], test[:, -1]\n",
    "    train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "    test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "    \n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(train_size, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    \n",
    "    #train model\n",
    "    history = model.fit(train_X, train_y, epochs=500, batch_size=72, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "    return history, model, train_X, train_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot MSE train/test\n",
    "def plotHistory(history):\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test and training set predictions over true data\n",
    "def plotPrediction(company, train_size, model, train_X, train_y, test_X, test_y):\n",
    "    plt.plot(range(len(train_y)+len(test_y)) , list(np.array(train_y))+list(np.array(test_y)), range(len(train_y)), model.predict(train_X), '-', range(len(train_y), len(train_y)+len(test_y)), model.predict(test_X), '-')\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Profit from previous day')\n",
    "    plt.title(company + ' - predicting stock market with Keras')\n",
    "    plt.legend([\"True Data\",\"Training Data\", \"Testing Data\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Predictions for Each Company\n",
    "def plotCompanies(companies, train_size, cols): \n",
    "    for company in companies: \n",
    "        # Fit model and predict for each company\n",
    "        history, model, train_X, train_y, test_X, test_y = predictCompany(company, train_size, cols)\n",
    "        # Plot Prediction Against True Profit for Each Company\n",
    "        plotPrediction(company, train_size, model, train_X, train_y, test_X, test_y)\n",
    "        # Plot Error for Each Company\n",
    "        plotHistory(history)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotCompanies(companies, train_size, stock_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean squared error for each company \n",
    "MSE_train_stock_only = []\n",
    "MSE_test_stock_only = []\n",
    "def calculateMSE(companies, train_size, MSE_train, MSE_test, cols): \n",
    "    for company in companies: \n",
    "        history, model, train_X, train_y, test_X, test_y = predictCompany(company, train_size, cols)\n",
    "        MSE_train_stock_only.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "        MSE_test_stock_only.append((company, mean_squared_error(model.predict(test_X), test_y)))\n",
    "calculateMSE(companies, train_size, MSE_train_stock_only, MSE_test_stock_only, stock_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE_train_stock_only)\n",
    "print(MSE_test_stock_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean squared error for each company \n",
    "MSE_train_trends_only = []\n",
    "MSE_test_trends_only = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    cols = [x.replace(\" \", \"_\") for x in kw_list if company in x]\n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(company, train_size, cols)\n",
    "    MSE_train_trends_only.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_trends_only.append((company, mean_squared_error(model.predict(test_X), test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE_train_trends_only)\n",
    "print(MSE_test_trends_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean squared error for each company \n",
    "MSE_train_both = []\n",
    "MSE_test_both = []\n",
    "for company in companies: \n",
    "    print(company)\n",
    "    cols = [x.replace(\" \", \"_\") for x in kw_list if company in x] + stock_columns\n",
    "    history, model, train_X, train_y, test_X, test_y = predictCompany(company, train_size, cols)\n",
    "    MSE_train_both.append((company, mean_squared_error(model.predict(train_X), train_y)))\n",
    "    MSE_test_both.append((company, mean_squared_error(model.predict(test_X), test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MSE_train_both)\n",
    "print(MSE_test_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
